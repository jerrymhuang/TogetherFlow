{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:40.948204Z",
     "start_time": "2025-07-27T15:38:40.912076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "71e7191bf6adf270",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:40.973831Z",
     "start_time": "2025-07-27T15:38:40.961682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    # set this to \"torch\", \"tensorflow\", or \"jax\"\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ],
   "id": "cf0cffd476ccf4cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:41.046799Z",
     "start_time": "2025-07-27T15:38:41.037366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:41.190092Z",
     "start_time": "2025-07-27T15:38:41.085452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from boundary_conditions import bound_agent_position\n",
    "from priors import complete_pooling_prior"
   ],
   "id": "7c7fb1f6daacee20",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:45.446226Z",
     "start_time": "2025-07-27T15:38:41.197236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "import bayesflow as bf\n",
    "import tensorflow as tf"
   ],
   "id": "6d81cae3105ed6bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 10:38:41.498602: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-27 10:38:41.577490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753630721.608925   17436 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753630721.617852   17436 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753630721.681925   17436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753630721.681939   17436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753630721.681940   17436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753630721.681941   17436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-27 10:38:41.691415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-27 10:38:45.384807: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-07-27 10:38:45.384861: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-07-27 10:38:45.384871: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: abracadabra\n",
      "2025-07-27 10:38:45.384876: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: abracadabra\n",
      "2025-07-27 10:38:45.385032: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 575.64.3\n",
      "2025-07-27 10:38:45.385065: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 575.64.3\n",
      "2025-07-27 10:38:45.385070: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 575.64.3\n",
      "INFO:bayesflow:Using backend 'tensorflow'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:45.502047Z",
     "start_time": "2025-07-27T15:38:45.465849Z"
    }
   },
   "cell_type": "code",
   "source": "bf.__version__",
   "id": "12ffcfc144e06ef5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:45.634688Z",
     "start_time": "2025-07-27T15:38:45.601701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trying numba again with a wrapper\n",
    "from numba import njit"
   ],
   "id": "7767e0f7213ad2d8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generative Model Definition\n",
    "\n",
    "The movement of any agent $a = 1, ..., A$ is both related to: 1) its interaction with surrounding neighbors $i = 1, ..., I$, which we call *internal influence*, and 2) their motivation to the surrounding spatial objects $b = 1, ..., B$, which we call *external influence*. These influences are modulated by a stationary weight, $w_a$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a, t} = w_a \\theta_{a|j, t} + (1 - w_a) \\theta_{a|i, t}.\n",
    "\\end{equation}"
   ],
   "id": "623755d3f637f5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta-Variables\n",
    "\n",
    "First, we define some meta-variables, such as the number of agents to simulate, the number of spatial beacons present in the environment, etc."
   ],
   "id": "7c597724cb72656c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:45.672478Z",
     "start_time": "2025-07-27T15:38:45.649892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_agents = 12\n",
    "num_beacons = 2\n",
    "room_size = (8., 10.)\n",
    "world_size = 25."
   ],
   "id": "e78ab1f1dba7dd9b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Agent Initialization",
   "id": "1d7e42c6024224dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:45.731510Z",
     "start_time": "2025-07-27T15:38:45.704355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_agents(\n",
    "    num_agents: int = 12,\n",
    "    room_size: tuple = (8., 10.),\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate random positions and orientations for agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100.0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        A tuple containing the positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate random positions within the boundary size centered at 0\n",
    "    x = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[0]\n",
    "    y = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[1]\n",
    "    positions = np.vstack((x, y)).T\n",
    "\n",
    "    # Generate random orientations (angles in radians between 0 and 2*pi)\n",
    "    rotations = np.random.random(size=(num_agents, )).astype(np.float32) * np.pi * 2\n",
    "\n",
    "    return positions.astype(np.float32), rotations.astype(np.float32)"
   ],
   "id": "69955ec69ce490f7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:46.440709Z",
     "start_time": "2025-07-27T15:38:45.756783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p, r = initialize_agents(room_size=room_size, num_agents=12)\n",
    "p"
   ],
   "id": "a1dfb303904be884",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15715909,  1.0016245 ],\n",
       "       [ 2.832931  ,  1.8684179 ],\n",
       "       [-0.39079976,  4.3459663 ],\n",
       "       [ 2.8210168 ,  2.6284523 ],\n",
       "       [ 3.7776475 , -3.410761  ],\n",
       "       [ 2.0081534 ,  4.6942735 ],\n",
       "       [ 2.1511912 ,  4.301675  ],\n",
       "       [-0.7819321 ,  0.8893734 ],\n",
       "       [ 0.97294426,  3.0981631 ],\n",
       "       [-0.01738811,  1.0164589 ],\n",
       "       [ 1.0862064 ,  1.1993265 ],\n",
       "       [ 1.6297746 ,  3.2795982 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Beacon Initialization",
   "id": "3cecc37ae822ed94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:46.498669Z",
     "start_time": "2025-07-27T15:38:46.467707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_beacons(\n",
    "        num_beacons = 10,\n",
    "        room_sensing_range = 50.\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize beacons following a uniform distribution scaled to the room's sensing boundary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_beacons : int, default: 10\n",
    "        Number of beacons to initialize.\n",
    "    room_sensing_range : float, default: 50.0\n",
    "        Sensing distance of the room for the beacons to matter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    beacons      : np.ndarray of shape (num_beacons, 2)\n",
    "        Initial positions of the beacons.\n",
    "    \"\"\"\n",
    "\n",
    "    beacons = (np.random.random(size=(num_beacons, 2)) - 0.5) * room_sensing_range\n",
    "    return beacons.astype(np.float32)"
   ],
   "id": "692d0c7b0c12d6b4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:46.674544Z",
     "start_time": "2025-07-27T15:38:46.527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "beacon_positions = initialize_beacons(num_beacons=1, room_sensing_range=world_size)\n",
    "beacon_positions"
   ],
   "id": "90efc1b2f6f33528",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.086244,  -7.680403]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## External Influence: drift-diffusion vector\n",
    "\n",
    "We want to compute the influence of agent movement direction within a single time step. For this, we specify our internal influence as a 2D drift diffusion model, where the agents are approach a spatial beacon within the room's boundary by reorienting its locomotive direction.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a|j, t} = \\theta_{a|j, t-1} + \\omega_a \\mathrm{d}t + \\mathrm{d}\\phi_t,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{d}\\mathbf{x}_{a|j, t}\n",
    "    &= v_{a|j}\\mathrm{d}t \\frac{\\mathbf{x}_{a|j}}{||\\mathbf{x}_{a|j}||} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t \\\\\n",
    "    &= v_{a}\\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|j, t} \\\\\n",
    "        \\sin \\theta_{a|j, t}\n",
    "    \\end{bmatrix} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t,% \\sqrt{\\mathrm{d}t} Z_t.\n",
    "\\end{align}"
   ],
   "id": "322fa08fd256efed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:47.069678Z",
     "start_time": "2025-07-27T15:38:47.041875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def external_influence(\n",
    "    agent_position,\n",
    "    beacon_position,\n",
    "    noise = False,\n",
    "    noise_amplitude = 0.01\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a drift-diffusion vector in 2D space for a single agent\n",
    "    based on a target location (in this case, the position of a beacon).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_position : np.ndarray\n",
    "        The position of the agent.\n",
    "    target_position : np.ndarray\n",
    "        The position of the target beacon.\n",
    "    focus : float, optional\n",
    "        The dispersion of a von Mises distribution for rotational noise influenced by the neighbors.\n",
    "        The higher the value is, the less perturbation there would be.\n",
    "    noise: bool, optional\n",
    "        Whether the focus is interpreted as noise amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D vector representing the drift-diffusion process towards the target (beacon).\n",
    "    \"\"\"\n",
    "    # Calculate the angle towards the beacon (in radian)\n",
    "    beacon_direction = np.arctan2(\n",
    "        beacon_position[1] - agent_position[1],\n",
    "        beacon_position[0] - agent_position[0]\n",
    "    )\n",
    "\n",
    "    # Generate a random direction with drift around the target angle\n",
    "    if noise:\n",
    "        beacon_direction = beacon_direction + (np.random.random() - 0.5) * noise_amplitude\n",
    "        # beacon_direction = beacon_direction + np.random.vonmises(0., 8.) * noise_amplitude\n",
    "\n",
    "    # Convert the angle to a unit vector in 2D space\n",
    "    v = np.array([np.cos(beacon_direction), np.sin(beacon_direction)], dtype=np.float32)\n",
    "\n",
    "    return v"
   ],
   "id": "9530303c0429c6e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Internal Influence: particle dynamics\n",
    "\n",
    "Its influence by a collective group of agents is modeled as a self-propelling particle system, as expressed in the Vicsek model:\n",
    "\n",
    "\\begin{align}\n",
    "    \\theta_{a|i, t} &= \\langle \\theta_{i, t}\\rangle_{|\\mathbf{x}_a - \\mathbf{x}_i| < r_a, i \\in I} + \\eta_{a,t-1}, \\\\\n",
    "    \\mathrm{d} \\mathbf{x}_{a|i,t} &= v_{a,t} \\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|i, t} \\\\\n",
    "        \\sin \\theta_{a|i, t}\n",
    "    \\end{bmatrix},\n",
    "\\end{align}"
   ],
   "id": "b8186c8f6083f763"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:47.277628Z",
     "start_time": "2025-07-27T15:38:47.213949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def internal_influence(\n",
    "        self_position,\n",
    "        other_positions,\n",
    "        other_rotations,\n",
    "        sensing_radius = 1.5,\n",
    "        focus = 0.01,\n",
    "        noise = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate an influence vector for a single agent\n",
    "    based on the angular component of the Vicsek model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the position of the agent\n",
    "    other_positions : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the positions of the neighboring agents.\n",
    "    other_rotations : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the rotations of the neighboring agents.\n",
    "    sensing_radius : float\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    focus : float, optional\n",
    "        The dispersion of a von Mises distribution for rotational noise influenced by the neighbors.\n",
    "        The higher the value is, the less perturbation there would be.\n",
    "    noise: bool, optional\n",
    "        Whether the focus is interpreted as noise amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D unit vector representing the averaged influence direction with added noise.\n",
    "    \"\"\"\n",
    "\n",
    "    neighbor_rotations = []\n",
    "\n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "\n",
    "        if d <= sensing_radius and d > 0:\n",
    "            neighbor_rotations.append(other_rotations[i])\n",
    "\n",
    "    if len(neighbor_rotations) == 0:\n",
    "        return np.array([0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "    neighbor_rotations = np.array(neighbor_rotations)\n",
    "    averaged_rotation = np.sum(neighbor_rotations) / len(neighbor_rotations)\n",
    "\n",
    "    if noise:\n",
    "        deviation = (np.random.random() - 0.5) * focus\n",
    "    else:\n",
    "        deviation = np.random.vonmises(mu=0., kappa=4.) * focus\n",
    "    direction = averaged_rotation + deviation\n",
    "\n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32)\n",
    "\n",
    "    return v"
   ],
   "id": "1f7129d3d52d1784",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting everything together: combined influences\n",
    "\n",
    "The combined influences allow us to update the agents' positions and rotations together."
   ],
   "id": "d0eb58db671d160c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:47.354080Z",
     "start_time": "2025-07-27T15:38:47.299290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def count_neighbors(self_position, other_positions, sensing_radius = 1.5):\n",
    "    \"\"\"\n",
    "    Helper function that counts the number of neighbors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position   : np.ndarray of size (2)\n",
    "        The position of the agent itself\n",
    "    other_positions : np.ndarray of size (num_agents, 2)\n",
    "        The positions of all agents\n",
    "    sensing_radius  : float, default: 1.5\n",
    "        The sensing radius of the agent\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_neighbors   : int, default: 0\n",
    "        The number of neighbors within the agent's sensing radius.\n",
    "    \"\"\"\n",
    "\n",
    "    num_neighbors = 0\n",
    "\n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "\n",
    "        if d <= sensing_radius and d > 0:\n",
    "            num_neighbors += 1\n",
    "\n",
    "    return num_neighbors"
   ],
   "id": "49222407ea620c8f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:47.508840Z",
     "start_time": "2025-07-27T15:38:47.373489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_neighbors = count_neighbors(p[8], p)\n",
    "num_neighbors"
   ],
   "id": "77764dbd1777e36b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:47.549737Z",
     "start_time": "2025-07-27T15:38:47.522951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def combined_influences(\n",
    "    agent_positions: np.ndarray = None,\n",
    "    agent_rotations: np.ndarray = None,\n",
    "    beacon_positions: np.ndarray = None,\n",
    "    velocity: float = 1.0,\n",
    "    sensing_radius: float = 2.5,\n",
    "    dt: float = 0.1,\n",
    "    influence_weight: float = 0.5,\n",
    "    internal_focus: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the positions and orientations of a single agent\n",
    "    based on velocity and influence vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_positions : np.ndarray\n",
    "        Current positions of the agents.\n",
    "    agent_rotations : np.ndarray\n",
    "        Current orientations of the agents.\n",
    "    beacon_positions : np.ndarray\n",
    "        Positions of the beacons.\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    dt : float, optional\n",
    "        The time step for updating positions and orientations (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight of influence_vector1 in determining new orientations (default is 0.7).\n",
    "    external_focus : float, optional\n",
    "        Concentration of the agent's rotational noise influenced by the beacons\n",
    "    internal_focus : float, optional\n",
    "        Concentration of the agent's rotational noise influenced by the neighbors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        Updated positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "\n",
    "    assert (len(agent_positions) == len(agent_rotations))\n",
    "\n",
    "    num_agents = agent_positions.shape[0]\n",
    "    num_beacons = beacon_positions.shape[0]\n",
    "\n",
    "    # Create new numpy arrays for the updated agent positions and rotations\n",
    "    new_agent_positions = np.zeros((num_agents, 2))\n",
    "    new_agent_rotations = np.zeros((num_agents, ))\n",
    "    num_neighbors = np.zeros((num_agents, ))\n",
    "\n",
    "\n",
    "    for i in range(num_agents):\n",
    "\n",
    "        num_neighbors[i] = count_neighbors(agent_positions[i], agent_positions)\n",
    "\n",
    "        # Generate the ddm vector for the agent based on its closest beacon\n",
    "        distance_to_beacon = []\n",
    "\n",
    "        for b in range(num_beacons):\n",
    "            bx = beacon_positions[b, 0] - agent_positions[i, 0]\n",
    "            by = beacon_positions[b, 1] - agent_positions[i, 1]\n",
    "            distance_to_beacon.append((bx * bx + by * by) ** 0.5)\n",
    "\n",
    "        beacon_id = np.argmin(np.array(distance_to_beacon))\n",
    "\n",
    "        ddm_vector = external_influence(\n",
    "            agent_positions[i],\n",
    "            beacon_positions[beacon_id],\n",
    "            #focus=external_focus\n",
    "        )\n",
    "\n",
    "        # Generate the vicsek vector for the agent based on its neighbors (all agents)\n",
    "        vicsek_vector = internal_influence(\n",
    "            self_position=agent_positions[i],\n",
    "            other_positions=agent_positions,\n",
    "            other_rotations=agent_rotations,\n",
    "            sensing_radius=sensing_radius,\n",
    "            focus=internal_focus\n",
    "        )\n",
    "\n",
    "        # Update orientations based on two influence vectors\n",
    "        ddm_influence = np.arctan2(ddm_vector[1], ddm_vector[0])\n",
    "        vicsek_influence = np.arctan2(vicsek_vector[1], vicsek_vector[0])\n",
    "\n",
    "        # Combine influences to update orientations with different weights\n",
    "        new_agent_rotations[i] = agent_rotations[i] + (influence_weight * ddm_influence + (1 - influence_weight) * vicsek_influence) * dt\n",
    "\n",
    "        # Ensure orientations are within the range [0, 2*pi]\n",
    "        new_agent_rotations[i] = np.mod(new_agent_rotations[i], 2 * np.pi)\n",
    "\n",
    "        # Update positions based on current orientations\n",
    "        new_agent_positions[i, 0] = agent_positions[i, 0] + velocity * np.cos(new_agent_rotations[i].item()) * dt\n",
    "        new_agent_positions[i, 1] = agent_positions[i, 1] + velocity * np.sin(new_agent_rotations[i].item()) * dt\n",
    "\n",
    "        new_agent_positions[i] = bound_agent_position(new_agent_positions[i], room_size=room_size)\n",
    "\n",
    "    return new_agent_positions, new_agent_rotations, num_neighbors"
   ],
   "id": "8745190d61c56ce3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.415205Z",
     "start_time": "2025-07-27T15:38:47.574716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_positions, agent_rotations = initialize_agents(12, room_size=room_size)\n",
    "beacon_positions = initialize_beacons(num_beacons=2)\n",
    "new_agent_positions, new_agent_rotations, num_neighbors = combined_influences(agent_positions, agent_rotations, beacon_positions)"
   ],
   "id": "6a12b3b4383bdf92",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.464150Z",
     "start_time": "2025-07-27T15:38:49.430882Z"
    }
   },
   "cell_type": "code",
   "source": "np.concatenate([agent_positions, new_agent_positions], axis=1)",
   "id": "6226b2947f10bc12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.04276466,  3.89841747,  2.13973271,  3.87397984],\n",
       "       [-0.96194196,  3.52170658, -0.98370297,  3.424103  ],\n",
       "       [-2.1507237 ,  2.72945166, -2.23885858,  2.68220504],\n",
       "       [ 1.72830009,  0.89522064,  1.80733946,  0.95648056],\n",
       "       [ 1.47903061, -3.74447107,  1.55036913, -3.67439387],\n",
       "       [-2.25255322,  1.87738419, -2.35248808,  1.88099321],\n",
       "       [ 0.43127775,  4.34173489,  0.5240099 ,  4.30430832],\n",
       "       [ 0.60735226, -4.6319375 ,  0.65531996, -4.71968201],\n",
       "       [ 0.70764017,  4.65200663,  0.61605027,  4.6921475 ],\n",
       "       [-1.44591546,  3.64905643, -1.36200107,  3.70344738],\n",
       "       [ 1.28609562, -4.53881311,  1.34047441, -4.62273538],\n",
       "       [-3.26457262, -3.77155113, -3.27925952, -3.67263554]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.548981Z",
     "start_time": "2025-07-27T15:38:49.523611Z"
    }
   },
   "cell_type": "code",
   "source": "np.vstack([agent_rotations, new_agent_rotations]).T",
   "id": "6d0bd9a3c2b38853",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.0382185 , 6.03630881],\n",
       "       [4.53555012, 4.49302377],\n",
       "       [3.41017032, 3.63367953],\n",
       "       [0.56766957, 0.65934497],\n",
       "       [0.72159046, 0.77647918],\n",
       "       [3.1696465 , 3.10549459],\n",
       "       [5.94487906, 5.89958053],\n",
       "       [4.97673845, 5.21267561],\n",
       "       [2.70993209, 2.72853827],\n",
       "       [0.57989484, 0.57508896],\n",
       "       [5.05512714, 5.28733312],\n",
       "       [1.64087987, 1.71819854]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.662712Z",
     "start_time": "2025-07-27T15:38:49.636610Z"
    }
   },
   "cell_type": "code",
   "source": "num_neighbors",
   "id": "ab7ef9d6df643aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 3., 0., 2., 1., 1., 2., 1., 2., 2., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation Loop\n",
    "\n",
    "The update allows us to continuously simulate the agents' positions and rotations at a given interval"
   ],
   "id": "25bfa1803f2f644a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.785539Z",
     "start_time": "2025-07-27T15:38:49.746803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit(parallel=True)\n",
    "def simulator_fun(\n",
    "    batch_size: int = 1,\n",
    "    theta = None,\n",
    "    num_agents: int = 12,\n",
    "    num_beacons: int = 1,\n",
    "    room_size: tuple = (8, 10),\n",
    "    velocity: float = 1.0,\n",
    "    dt: float = 0.001,\n",
    "    influence_weight: float = 0.7,\n",
    "    sensing_radius: float = 10.0,\n",
    "    internal_focus: float = 0.1,\n",
    "    time_horizon: float = 30.\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the simulation and store the time series of positions and orientations of agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : np.ndarray\n",
    "        Prior parameters specifying the internal properties of the agents\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    num_beacons : int, optional\n",
    "        Number of beacons to generate (default is 1).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100).\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    dt : float, optional\n",
    "        The time step for the update (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight for influence_vector1 in determining new orientations (default is 0.7).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius for the Vicsek model (default is 10.0).\n",
    "    num_timesteps : int, optional\n",
    "        The number of steps to simulate (default is 100).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        The time series of positions and orientations of the agents.\n",
    "    \"\"\"\n",
    "\n",
    "    if theta is not None:\n",
    "        influence_weight = theta[0]\n",
    "        sensing_radius = theta[1]\n",
    "        velocity = theta[2]\n",
    "        #internal_focus = theta[3]\n",
    "\n",
    "\n",
    "    num_timesteps = int(time_horizon / dt)\n",
    "\n",
    "    # Apply radial bound with sigmoid transformation for the sensing radius\n",
    "    # (r_min, r_max) = (1., 5.)\n",
    "    # sensing_radius = r_min + (r_max - r_min) * (1. / (1. + np.exp(-sensing_radius)))\n",
    "\n",
    "    # Initialize arrays to store time series of positions and orientations\n",
    "    for b in range(batch_size):\n",
    "        positions = np.zeros((num_timesteps, num_agents, 2))\n",
    "        rotations = np.zeros((num_timesteps, num_agents, ))\n",
    "        neighbors = np.zeros((num_timesteps, num_agents, ))\n",
    "\n",
    "            # Initialize positions and orientations\n",
    "        initial_positions, initial_rotations = initialize_agents(num_agents, room_size=room_size)\n",
    "        positions[0] = initial_positions\n",
    "        rotations[0] = initial_rotations\n",
    "\n",
    "        # Initialize beacons\n",
    "        beacon_positions = initialize_beacons(num_beacons)\n",
    "\n",
    "        # Simulation loop\n",
    "        for t in range(1, num_timesteps):\n",
    "            ps, rs, num_neighbors = combined_influences(\n",
    "                agent_positions=positions[t-1],\n",
    "                agent_rotations=rotations[t-1],\n",
    "                beacon_positions=beacon_positions,\n",
    "                velocity=velocity,\n",
    "                sensing_radius=sensing_radius,\n",
    "                dt=dt,\n",
    "                influence_weight=influence_weight,\n",
    "                internal_focus=internal_focus\n",
    "            )\n",
    "\n",
    "            # Store positions and orientations for each time step\n",
    "            positions[t] = ps\n",
    "            rotations[t] = rs\n",
    "            neighbors[t] = num_neighbors\n",
    "\n",
    "        neighbors[0] = neighbors[1]\n",
    "\n",
    "        rotations = rotations[:,:,np.newaxis]\n",
    "        neighbors = neighbors[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "    return np.concatenate((positions, rotations, neighbors), axis=-1)"
   ],
   "id": "ffcbc6acb0544952",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.844141Z",
     "start_time": "2025-07-27T15:38:49.816418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TogetherFlowSimulator:\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_agents: int = 12,\n",
    "                 num_beacons: int = 1,\n",
    "                 room_size: tuple = (8, 10),\n",
    "                 dt: float = 0.001,\n",
    "                 internal_focus: float = 0.1,\n",
    "                 time_horizon: float = 30.\n",
    "                 ):\n",
    "        self.num_agents = num_agents\n",
    "        self.num_beacons = num_beacons\n",
    "        self.room_size = room_size\n",
    "        self.dt = dt\n",
    "        self.internal_focus = internal_focus\n",
    "        self.time_horizon = time_horizon\n",
    "\n",
    "\n",
    "    def sample(self, batch_shape: int | tuple = (1,)) -> dict[str, np.ndarray]:\n",
    "\n",
    "        batch_size = batch_shape[0]\n",
    "        thetas = []\n",
    "        samples = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            theta = complete_pooling_prior()\n",
    "            sim = simulator_fun(\n",
    "                theta=theta,\n",
    "                num_agents=self.num_agents,\n",
    "                num_beacons=self.num_beacons,\n",
    "                room_size=self.room_size,\n",
    "                dt=self.dt,\n",
    "                internal_focus=self.internal_focus,\n",
    "                time_horizon=self.time_horizon\n",
    "            )\n",
    "            thetas.append(theta)\n",
    "            samples.append(sim)\n",
    "\n",
    "        thetas = np.array(thetas)\n",
    "        samples = np.array(samples)\n",
    "\n",
    "        return dict(\n",
    "            w = thetas[:,0],\n",
    "            r = thetas[:,1],\n",
    "            v = thetas[:,2],\n",
    "            positions = samples[:,:,:,0:2],\n",
    "            rotations = samples[:,:,:,2],\n",
    "            neighbors = samples[:,:,:,3]\n",
    "        )"
   ],
   "id": "a3fd7c62de2ff278",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:49.897741Z",
     "start_time": "2025-07-27T15:38:49.872140Z"
    }
   },
   "cell_type": "code",
   "source": "simulator = TogetherFlowSimulator(num_agents=49)",
   "id": "77d5a1f3641a32af",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:59.300048Z",
     "start_time": "2025-07-27T15:38:49.923333Z"
    }
   },
   "cell_type": "code",
   "source": "test_sims = simulator.sample(batch_shape=(10,))",
   "id": "d023cd448fdc688",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:59.343234Z",
     "start_time": "2025-07-27T15:38:59.313196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(test_sims['w'].shape)\n",
    "print(test_sims['r'].shape)\n",
    "print(test_sims['v'].shape)\n",
    "print(test_sims['positions'].shape)\n",
    "print(test_sims['rotations'].shape)\n",
    "print(test_sims['neighbors'].shape)"
   ],
   "id": "41bfaf2c0c7a136c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10, 30000, 49, 2)\n",
      "(10, 30000, 49)\n",
      "(10, 30000, 49)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Priors",
   "id": "f581a8b8107de537"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adapter",
   "id": "c7d3e491282812d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:38:59.410172Z",
     "start_time": "2025-07-27T15:38:59.384127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .as_time_series([\"positions\", \"rotations\", \"neighbors\"])\n",
    "    .expand_dims(['rotations', 'neighbors'], axis=-1)\n",
    "    .expand_dims(['w', 'r', 'v'], axis=-1)\n",
    "    .concatenate(['w', 'r', 'v'], into=\"inference_variables\")\n",
    "    .concatenate([\"positions\", \"rotations\", \"neighbors\"], into=\"summary_variables\", axis=-1)\n",
    ")"
   ],
   "id": "69137094735b10b1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:39:00.932639Z",
     "start_time": "2025-07-27T15:38:59.440608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adapted_simulator = TogetherFlowSimulator(num_agents=49)\n",
    "adapter_sim = adapter(adapted_simulator.sample(batch_shape=(2,)))"
   ],
   "id": "d452bff0a8f006f7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:39:00.967710Z",
     "start_time": "2025-07-27T15:39:00.946395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(adapter_sim['summary_variables'].shape)\n",
    "print(adapter_sim['inference_variables'].shape)"
   ],
   "id": "94267ce51c15bc59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30000, 49, 4)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Approximator",
   "id": "bb6da22bb3c43d6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:43:47.861596Z",
     "start_time": "2025-07-27T15:43:47.832335Z"
    }
   },
   "cell_type": "code",
   "source": "from bayesflow.networks import SummaryNetwork",
   "id": "c666e214434b7ffa",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:43:48.283505Z",
     "start_time": "2025-07-27T15:43:48.257663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HierarchicalNetwork(SummaryNetwork):\n",
    "\n",
    "\n",
    "    def __init__(self, networks, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.networks = networks\n",
    "\n",
    "    def call(self, x, return_all=False, **kwargs):\n",
    "\n",
    "        if return_all:\n",
    "            outputs = []\n",
    "            for net in self.networks:\n",
    "                x = net(x, **kwargs)\n",
    "                outputs.append(x)\n",
    "            return outputs\n",
    "        else:\n",
    "            for net in self.networks:\n",
    "                x = net(x, **kwargs)\n",
    "            return x\n",
    "\n"
   ],
   "id": "a96a61ad3bcfccff",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:43:51.690425Z",
     "start_time": "2025-07-27T15:43:51.627412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How do we go about the summary network, since HierarchicalNetwork has not been implemented yet?\n",
    "\n",
    "# Need to ask Stefan about this.\n",
    "summary_net = HierarchicalNetwork([\n",
    "    keras.layers.TimeDistributed(tf.keras.layers.LSTM(units=256)),\n",
    "    keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1))\n",
    "])"
   ],
   "id": "a45ebbfd8f0a1a38",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:43:52.531440Z",
     "start_time": "2025-07-27T15:43:52.442670Z"
    }
   },
   "cell_type": "code",
   "source": "inference_net = bf.networks.FlowMatching()",
   "id": "e31c14fc18c97048",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:43:52.889164Z",
     "start_time": "2025-07-27T15:43:52.839119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = bf.workflows.BasicWorkflow(\n",
    "    simulator=adapted_simulator,\n",
    "    adapter=adapter,\n",
    "    inference_network=inference_net,\n",
    "    summary_network=summary_net,\n",
    ")"
   ],
   "id": "6a4a56474df53e0a",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-27T15:57:29.286433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = workflow.simulate((200,))\n",
    "test_set = workflow.simulate((10,))"
   ],
   "id": "291b97683c82f7ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T15:53:40.696596Z",
     "start_time": "2025-07-27T15:46:30.944857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = workflow.fit_offline(\n",
    "    data=train_set,\n",
    "    validation_set=test_set,\n",
    "    batch_size=32,\n",
    "    epochs=1\n",
    ")"
   ],
   "id": "65a6ecfd4c7bd774",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OfflineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[32m/tmp/ipykernel_17436/4205908186.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m history = workflow.fit_offline(\n\u001B[32m      2\u001B[39m     data=train_set,\n\u001B[32m      3\u001B[39m     validation_set=test_set,\n\u001B[32m      4\u001B[39m     batch_size=\u001B[32m32\u001B[39m,\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/workflows/basic_workflow.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, data, epochs, batch_size, keep_optimizer, validation_data, augmentations, **kwargs)\u001B[39m\n\u001B[32m    718\u001B[39m         \"\"\"\n\u001B[32m    719\u001B[39m \n\u001B[32m    720\u001B[39m         dataset = OfflineDataset(data=data, batch_size=batch_size, adapter=self.adapter, augmentations=augmentations)\n\u001B[32m    721\u001B[39m \n\u001B[32m--> \u001B[39m\u001B[32m722\u001B[39m         return self._fit(\n\u001B[32m    723\u001B[39m             dataset,\n\u001B[32m    724\u001B[39m             epochs,\n\u001B[32m    725\u001B[39m             strategy=\u001B[33m\"offline\"\u001B[39m,\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/workflows/basic_workflow.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, dataset, epochs, strategy, keep_optimizer, validation_data, **kwargs)\u001B[39m\n\u001B[32m    967\u001B[39m             self._on_training_finished()\n\u001B[32m    968\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self.history\n\u001B[32m    969\u001B[39m         \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    970\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m keep_optimizer:\n\u001B[32m--> \u001B[39m\u001B[32m971\u001B[39m                 self.optimizer = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/continuous_approximator.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    311\u001B[39m         ------\n\u001B[32m    312\u001B[39m         ValueError\n\u001B[32m    313\u001B[39m             If both `dataset` \u001B[38;5;28;01mand\u001B[39;00m `simulator` are provided \u001B[38;5;28;01mor\u001B[39;00m neither \u001B[38;5;28;01mis\u001B[39;00m provided.\n\u001B[32m    314\u001B[39m         \"\"\"\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m super().fit(*args, **kwargs, adapter=self.adapter)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/approximator.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, dataset, simulator, **kwargs)\u001B[39m\n\u001B[32m    133\u001B[39m             logging.info(\u001B[33m\"Building on a test batch.\"\u001B[39m)\n\u001B[32m    134\u001B[39m             mock_data = dataset[\u001B[32m0\u001B[39m]\n\u001B[32m    135\u001B[39m             mock_data = keras.tree.map_structure(keras.ops.convert_to_tensor, mock_data)\n\u001B[32m    136\u001B[39m             mock_data_shapes = keras.tree.map_structure(keras.ops.shape, mock_data)\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m             self.build(mock_data_shapes)\n\u001B[32m    138\u001B[39m \n\u001B[32m    139\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m super().fit(dataset=dataset, **kwargs)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    228\u001B[39m         @wraps(original_build_method)\n\u001B[32m    229\u001B[39m         \u001B[38;5;28;01mdef\u001B[39;00m build_wrapper(*args, **kwargs):\n\u001B[32m    230\u001B[39m             \u001B[38;5;28;01mwith\u001B[39;00m obj._open_name_scope():\n\u001B[32m    231\u001B[39m                 obj._path = current_path()\n\u001B[32m--> \u001B[39m\u001B[32m232\u001B[39m                 original_build_method(*args, **kwargs)\n\u001B[32m    233\u001B[39m             \u001B[38;5;66;03m# Record build config.\u001B[39;00m\n\u001B[32m    234\u001B[39m             signature = inspect.signature(original_build_method)\n\u001B[32m    235\u001B[39m             obj._build_shapes_dict = signature.bind(*args, **kwargs).arguments\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/continuous_approximator.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, data_shapes)\u001B[39m\n\u001B[32m     75\u001B[39m         \u001B[38;5;66;03m# Build summary network and get output shape if present\u001B[39;00m\n\u001B[32m     76\u001B[39m         summary_outputs_shape = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     77\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m self.summary_network \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     78\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m self.summary_network.built:\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m                 self.summary_network.build(data_shapes[\u001B[33m\"summary_variables\"\u001B[39m])\n\u001B[32m     80\u001B[39m             summary_outputs_shape = self.summary_network.compute_output_shape(data_shapes[\u001B[33m\"summary_variables\"\u001B[39m])\n\u001B[32m     81\u001B[39m \n\u001B[32m     82\u001B[39m         \u001B[38;5;66;03m# Compute inference_conditions_shape by combining original and summary outputs\u001B[39;00m\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    228\u001B[39m         @wraps(original_build_method)\n\u001B[32m    229\u001B[39m         \u001B[38;5;28;01mdef\u001B[39;00m build_wrapper(*args, **kwargs):\n\u001B[32m    230\u001B[39m             \u001B[38;5;28;01mwith\u001B[39;00m obj._open_name_scope():\n\u001B[32m    231\u001B[39m                 obj._path = current_path()\n\u001B[32m--> \u001B[39m\u001B[32m232\u001B[39m                 original_build_method(*args, **kwargs)\n\u001B[32m    233\u001B[39m             \u001B[38;5;66;03m# Record build config.\u001B[39;00m\n\u001B[32m    234\u001B[39m             signature = inspect.signature(original_build_method)\n\u001B[32m    235\u001B[39m             obj._build_shapes_dict = signature.bind(*args, **kwargs).arguments\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/utils/decorators.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m             \u001B[38;5;28;01melif\u001B[39;00m len(args) > argpos:\n\u001B[32m     92\u001B[39m                 args = list(args)\n\u001B[32m     93\u001B[39m                 args[argpos] = callback(args[argpos])\n\u001B[32m     94\u001B[39m \n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m fn(*args, **kwargs)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/networks/summary_network.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, input_shape)\u001B[39m\n\u001B[32m     15\u001B[39m     @sanitize_input_shape\n\u001B[32m     16\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m build(self, input_shape):\n\u001B[32m     17\u001B[39m         x = keras.ops.zeros(input_shape)\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m         z = self.call(x)\n\u001B[32m     19\u001B[39m \n\u001B[32m     20\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m self.base_distribution \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     21\u001B[39m             self.base_distribution.build(keras.ops.shape(z))\n",
      "\u001B[32m/tmp/ipykernel_17436/94233699.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, x, return_all, **kwargs)\u001B[39m\n\u001B[32m     14\u001B[39m                 outputs.append(x)\n\u001B[32m     15\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n\u001B[32m     16\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     17\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m net \u001B[38;5;28;01min\u001B[39;00m self.networks:\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m                 x = net(x, **kwargs)\n\u001B[32m     19\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    120\u001B[39m             \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m             \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m    122\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m         \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m             \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    970\u001B[39m                     \u001B[33m\"layers will not see the mask.\"\u001B[39m\n\u001B[32m    971\u001B[39m                 )\n\u001B[32m    972\u001B[39m         \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    973\u001B[39m             \u001B[38;5;66;03m# Destroy call context if we created it\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m974\u001B[39m             self._maybe_reset_call_context()\n\u001B[32m    975\u001B[39m \n\u001B[32m    976\u001B[39m         \u001B[38;5;66;03m################################################\u001B[39;00m\n\u001B[32m    977\u001B[39m         \u001B[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001B[39;00m\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    120\u001B[39m             \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m             \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m    122\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m         \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m             \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     54\u001B[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001B[32m     55\u001B[39m                 call_fn,\n\u001B[32m     56\u001B[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001B[32m     57\u001B[39m             )\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m call_fn(*args, **kwargs)\n\u001B[32m     59\u001B[39m \n\u001B[32m     60\u001B[39m         \u001B[38;5;66;03m# Plain flow.\u001B[39;00m\n\u001B[32m     61\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    213\u001B[39m                 new_e = e\n\u001B[32m    214\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m new_e.with_traceback(e.__traceback__) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    215\u001B[39m         \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    216\u001B[39m             \u001B[38;5;28;01mdel\u001B[39;00m signature\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m             \u001B[38;5;28;01mdel\u001B[39;00m bound_signature\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/time_distributed.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, inputs, training, mask)\u001B[39m\n\u001B[32m    122\u001B[39m         \u001B[38;5;66;03m# Implementation #1: is the time axis is static, use a Python for loop.\u001B[39;00m\n\u001B[32m    123\u001B[39m \n\u001B[32m    124\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m inputs.shape[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    125\u001B[39m             outputs = ops.stack(\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m                 [step_function(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;28;01min\u001B[39;00m range(inputs.shape[\u001B[32m0\u001B[39m])]\n\u001B[32m    127\u001B[39m             )\n\u001B[32m    128\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m time_distributed_transpose(outputs)\n\u001B[32m    129\u001B[39m \n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/time_distributed.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(i)\u001B[39m\n\u001B[32m    116\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m self.layer._call_has_mask_arg \u001B[38;5;28;01mand\u001B[39;00m mask \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    117\u001B[39m                 kwargs[\u001B[33m\"mask\"\u001B[39m] = mask[i]\n\u001B[32m    118\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m self.layer._call_has_training_arg:\n\u001B[32m    119\u001B[39m                 kwargs[\u001B[33m\"training\"\u001B[39m] = training\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self.layer.call(inputs[i], **kwargs)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, sequences, initial_state, mask, training)\u001B[39m\n\u001B[32m    582\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m call(self, sequences, initial_state=\u001B[38;5;28;01mNone\u001B[39;00m, mask=\u001B[38;5;28;01mNone\u001B[39;00m, training=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m583\u001B[39m         return super().call(\n\u001B[32m    584\u001B[39m             sequences, mask=mask, training=training, initial_state=initial_state\n\u001B[32m    585\u001B[39m         )\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, sequences, initial_state, mask, training)\u001B[39m\n\u001B[32m    402\u001B[39m         self._maybe_config_dropout_masks(\n\u001B[32m    403\u001B[39m             self.cell, sequences[:, \u001B[32m0\u001B[39m, :], initial_state\n\u001B[32m    404\u001B[39m         )\n\u001B[32m    405\u001B[39m \n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m         last_output, outputs, states = self.inner_loop(\n\u001B[32m    407\u001B[39m             sequences=sequences,\n\u001B[32m    408\u001B[39m             initial_state=initial_state,\n\u001B[32m    409\u001B[39m             mask=mask,\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, sequences, initial_state, mask, training)\u001B[39m\n\u001B[32m    574\u001B[39m                 \u001B[33m\"but cuDNN is not supported for this layer configuration \"\u001B[39m\n\u001B[32m    575\u001B[39m                 \u001B[33m\"with this backend. Pass use_cudnn='auto' to fallback \"\u001B[39m\n\u001B[32m    576\u001B[39m                 \u001B[33m\"to a non-cuDNN implementation.\"\u001B[39m\n\u001B[32m    577\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m578\u001B[39m         return super().inner_loop(\n\u001B[32m    579\u001B[39m             sequences, initial_state, mask=mask, training=training\n\u001B[32m    580\u001B[39m         )\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, sequences, initial_state, mask, training)\u001B[39m\n\u001B[32m    342\u001B[39m \n\u001B[32m    343\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m tree.is_nested(initial_state):\n\u001B[32m    344\u001B[39m             initial_state = [initial_state]\n\u001B[32m    345\u001B[39m \n\u001B[32m--> \u001B[39m\u001B[32m346\u001B[39m         return backend.rnn(\n\u001B[32m    347\u001B[39m             step,\n\u001B[32m    348\u001B[39m             sequences,\n\u001B[32m    349\u001B[39m             initial_state,\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001B[39m\n\u001B[32m    241\u001B[39m                 tensor_array_name=f\"input_ta_{i}\",\n\u001B[32m    242\u001B[39m             )\n\u001B[32m    243\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m i, inp \u001B[38;5;28;01min\u001B[39;00m enumerate(flattened_inputs)\n\u001B[32m    244\u001B[39m         )\n\u001B[32m--> \u001B[39m\u001B[32m245\u001B[39m         input_ta = tuple(\n\u001B[32m    246\u001B[39m             (\n\u001B[32m    247\u001B[39m                 ta.unstack(input_)\n\u001B[32m    248\u001B[39m                 \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m go_backwards\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    245\u001B[39m         \u001B[38;5;28;01mdef\u001B[39;00m _get_input_tensor(time):\n\u001B[32m    246\u001B[39m             inp = [t_[time] \u001B[38;5;28;01mfor\u001B[39;00m t_ \u001B[38;5;28;01min\u001B[39;00m processed_input]\n\u001B[32m--> \u001B[39m\u001B[32m247\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m tree.pack_sequence_as(inputs, inp)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/util/tf_should_use.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    287\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m wrapped(*args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m288\u001B[39m       return _add_should_use_warning(fn(*args, **kwargs),\n\u001B[32m    289\u001B[39m                                      warn_in_eager=warn_in_eager,\n\u001B[32m    290\u001B[39m                                      error_in_function=error_in_function)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, value, name)\u001B[39m\n\u001B[32m   1263\u001B[39m \n\u001B[32m   1264\u001B[39m     Raises:\n\u001B[32m   1265\u001B[39m       ValueError: \u001B[38;5;28;01mif\u001B[39;00m the shape inference fails.\n\u001B[32m   1266\u001B[39m     \"\"\"\n\u001B[32m-> \u001B[39m\u001B[32m1267\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m self._implementation.unstack(value, name=name)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, value, name)\u001B[39m\n\u001B[32m    906\u001B[39m   \u001B[38;5;28;01mdef\u001B[39;00m unstack(self, value, name=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    907\u001B[39m     \u001B[33m\"\"\"See TensorArray.\"\"\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m908\u001B[39m     tensors = array_ops_stack.unstack(value, name=name)\n\u001B[32m    909\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m len(tensors) > len(self._tensor_array) \u001B[38;5;28;01mand\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m self._dynamic_size:\n\u001B[32m    910\u001B[39m       raise ValueError(\n\u001B[32m    911\u001B[39m           \u001B[33m\"Cannot unstack %d tensors into a TensorArray of static size %d \"\u001B[39m %\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    151\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m Exception \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    153\u001B[39m       \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    154\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m       \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m   1257\u001B[39m \n\u001B[32m   1258\u001B[39m       \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[32m   1259\u001B[39m       \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1260\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(*args, **kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m1261\u001B[39m       \u001B[38;5;28;01mexcept\u001B[39;00m (TypeError, ValueError):\n\u001B[32m   1262\u001B[39m         \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[32m   1263\u001B[39m         \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[32m   1264\u001B[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/ops/array_ops_stack.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(value, num, axis, name)\u001B[39m\n\u001B[32m    210\u001B[39m                          f\"[{-value_shape.ndims}, {value_shape.ndims})\")\n\u001B[32m    211\u001B[39m       num = value_shape.dims[axis].value\n\u001B[32m    212\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m num \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    213\u001B[39m       \u001B[38;5;28;01mraise\u001B[39;00m ValueError(f\"Cannot infer argument `num` from shape {value_shape}\")\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m gen_array_ops.unpack(value, num=num, axis=axis, name=name)\n",
      "\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_array_ops.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(value, num, axis, name)\u001B[39m\n\u001B[32m  12844\u001B[39m         _ctx, \u001B[33m\"Unpack\"\u001B[39m, name, value, \u001B[33m\"num\"\u001B[39m, num, \u001B[33m\"axis\"\u001B[39m, axis)\n\u001B[32m  12845\u001B[39m       \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[32m  12846\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m _core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m  12847\u001B[39m       _ops.raise_from_not_ok_status(e, name)\n\u001B[32m> \u001B[39m\u001B[32m12848\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m _core._FallbackException:\n\u001B[32m  12849\u001B[39m       \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m  12850\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m  12851\u001B[39m       return unpack_eager_fallback(\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plots = workflow.plot_default_diagnostics(\n",
    "\n",
    ")"
   ],
   "id": "9283779c089c873d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
