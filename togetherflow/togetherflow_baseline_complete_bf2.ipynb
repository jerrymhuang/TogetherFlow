{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:11.461656Z",
     "start_time": "2025-06-25T02:19:11.370569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "71e7191bf6adf270",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:12.669155Z",
     "start_time": "2025-06-25T02:19:11.761532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    # set this to \"torch\", \"tensorflow\", or \"jax\"\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ],
   "id": "cf0cffd476ccf4cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:13.311048Z",
     "start_time": "2025-06-25T02:19:13.204792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:13.640714Z",
     "start_time": "2025-06-25T02:19:13.359541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from boundary_conditions import bound_agent_position\n",
    "from priors import complete_pooling_prior"
   ],
   "id": "7c7fb1f6daacee20",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:16.988725Z",
     "start_time": "2025-06-25T02:19:13.704699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "\n",
    "import bayesflow as bf"
   ],
   "id": "6d81cae3105ed6bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Using backend 'tensorflow'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:29.312709Z",
     "start_time": "2025-06-25T02:19:29.102845Z"
    }
   },
   "cell_type": "code",
   "source": "bf.__version__",
   "id": "12ffcfc144e06ef5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:31.525773Z",
     "start_time": "2025-06-25T02:19:31.294318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trying numba again with a wrapper\n",
    "from numba import njit"
   ],
   "id": "7767e0f7213ad2d8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generative Model Definition\n",
    "\n",
    "The movement of any agent $a = 1, ..., A$ is both related to: 1) its interaction with surrounding neighbors $i = 1, ..., I$, which we call *internal influence*, and 2) their motivation to the surrounding spatial objects $b = 1, ..., B$, which we call *external influence*. These influences are modulated by a stationary weight, $w_a$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a, t} = w_a \\theta_{a|j, t} + (1 - w_a) \\theta_{a|i, t}.\n",
    "\\end{equation}"
   ],
   "id": "623755d3f637f5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta-Variables\n",
    "\n",
    "First, we define some meta-variables, such as the number of agents to simulate, the number of spatial beacons present in the environment, etc."
   ],
   "id": "7c597724cb72656c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:35.533501Z",
     "start_time": "2025-06-25T02:19:35.319173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_agents = 12\n",
    "num_beacons = 2\n",
    "room_size = (8., 10.)\n",
    "world_size = 25."
   ],
   "id": "e78ab1f1dba7dd9b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Agent Initialization",
   "id": "1d7e42c6024224dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:38.107036Z",
     "start_time": "2025-06-25T02:19:37.892657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_agents(\n",
    "    num_agents: int = 12,\n",
    "    room_size: tuple = (8., 10.),\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate random positions and orientations for agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100.0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        A tuple containing the positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate random positions within the boundary size centered at 0\n",
    "    x = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[0]\n",
    "    y = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[1]\n",
    "    positions = np.vstack((x, y)).T\n",
    "\n",
    "    # Generate random orientations (angles in radians between 0 and 2*pi)\n",
    "    rotations = np.random.random(size=(num_agents, )).astype(np.float32) * np.pi * 2\n",
    "\n",
    "    return positions.astype(np.float32), rotations.astype(np.float32)"
   ],
   "id": "69955ec69ce490f7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:42.495200Z",
     "start_time": "2025-06-25T02:19:40.891850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p, r = initialize_agents(room_size=room_size, num_agents=12)\n",
    "p"
   ],
   "id": "a1dfb303904be884",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8905754 ,  1.4589584 ],\n",
       "       [ 2.1898522 ,  1.6008586 ],\n",
       "       [ 2.3473916 ,  1.2246871 ],\n",
       "       [ 3.828178  ,  3.534947  ],\n",
       "       [-3.55718   ,  0.1521051 ],\n",
       "       [-1.8361125 , -3.9373806 ],\n",
       "       [ 1.8271971 ,  3.7624621 ],\n",
       "       [ 2.5385213 , -4.4558144 ],\n",
       "       [ 3.9155002 , -1.4963915 ],\n",
       "       [-0.21458626, -3.4787445 ],\n",
       "       [-0.48741913, -4.474484  ],\n",
       "       [ 1.3265772 ,  1.29085   ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Beacon Initialization",
   "id": "3cecc37ae822ed94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:45.849298Z",
     "start_time": "2025-06-25T02:19:45.633699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_beacons(\n",
    "        num_beacons = 10,\n",
    "        room_sensing_range = 50.\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize beacons following a uniform distribution scaled to the room's sensing boundary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_beacons : int, default: 10\n",
    "        Number of beacons to initialize.\n",
    "    room_sensing_range : float, default: 50.0\n",
    "        Sensing distance of the room for the beacons to matter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    beacons      : np.ndarray of shape (num_beacons, 2)\n",
    "        Initial positions of the beacons.\n",
    "    \"\"\"\n",
    "\n",
    "    beacons = (np.random.random(size=(num_beacons, 2)) - 0.5) * room_sensing_range\n",
    "    return beacons.astype(np.float32)"
   ],
   "id": "692d0c7b0c12d6b4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:49.575094Z",
     "start_time": "2025-06-25T02:19:48.915419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "beacon_positions = initialize_beacons(num_beacons=1, room_sensing_range=world_size)\n",
    "beacon_positions"
   ],
   "id": "90efc1b2f6f33528",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.887549,  4.003112]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## External Influence: drift-diffusion vector\n",
    "\n",
    "We want to compute the influence of agent movement direction within a single time step. For this, we specify our internal influence as a 2D drift diffusion model, where the agents are approach a spatial beacon within the room's boundary by reorienting its locomotive direction.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a|j, t} = \\theta_{a|j, t-1} + \\omega_a \\mathrm{d}t + \\mathrm{d}\\phi_t,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{d}\\mathbf{x}_{a|j, t}\n",
    "    &= v_{a|j}\\mathrm{d}t \\frac{\\mathbf{x}_{a|j}}{||\\mathbf{x}_{a|j}||} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t \\\\\n",
    "    &= v_{a}\\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|j, t} \\\\\n",
    "        \\sin \\theta_{a|j, t}\n",
    "    \\end{bmatrix} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t,% \\sqrt{\\mathrm{d}t} Z_t.\n",
    "\\end{align}"
   ],
   "id": "322fa08fd256efed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:19:55.017854Z",
     "start_time": "2025-06-25T02:19:54.818762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def external_influence(\n",
    "    agent_position,\n",
    "    beacon_position,\n",
    "    noise = False,\n",
    "    noise_amplitude = 0.01\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a drift-diffusion vector in 2D space for a single agent\n",
    "    based on a target location (in this case, the position of a beacon).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_position : np.ndarray\n",
    "        The position of the agent.\n",
    "    target_position : np.ndarray\n",
    "        The position of the target beacon.\n",
    "    focus : float, optional\n",
    "        The dispersion of a von Mises distribution for rotational noise influenced by the neighbors.\n",
    "        The higher the value is, the less perturbation there would be.\n",
    "    noise: bool, optional\n",
    "        Whether the focus is interpreted as noise amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D vector representing the drift-diffusion process towards the target (beacon).\n",
    "    \"\"\"\n",
    "    # Calculate the angle towards the beacon (in radian)\n",
    "    beacon_direction = np.arctan2(\n",
    "        beacon_position[1] - agent_position[1],\n",
    "        beacon_position[0] - agent_position[0]\n",
    "    )\n",
    "\n",
    "    # Generate a random direction with drift around the target angle\n",
    "    if noise:\n",
    "        beacon_direction = beacon_direction + (np.random.random() - 0.5) * noise_amplitude\n",
    "        # beacon_direction = beacon_direction + np.random.vonmises(0., 8.) * noise_amplitude\n",
    "\n",
    "    # Convert the angle to a unit vector in 2D space\n",
    "    v = np.array([np.cos(beacon_direction), np.sin(beacon_direction)], dtype=np.float32)\n",
    "\n",
    "    return v"
   ],
   "id": "9530303c0429c6e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Internal Influence: particle dynamics\n",
    "\n",
    "Its influence by a collective group of agents is modeled as a self-propelling particle system, as expressed in the Vicsek model:\n",
    "\n",
    "\\begin{align}\n",
    "    \\theta_{a|i, t} &= \\langle \\theta_{i, t}\\rangle_{|\\mathbf{x}_a - \\mathbf{x}_i| < r_a, i \\in I} + \\eta_{a,t-1}, \\\\\n",
    "    \\mathrm{d} \\mathbf{x}_{a|i,t} &= v_{a,t} \\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|i, t} \\\\\n",
    "        \\sin \\theta_{a|i, t}\n",
    "    \\end{bmatrix},\n",
    "\\end{align}"
   ],
   "id": "b8186c8f6083f763"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:01.107900Z",
     "start_time": "2025-06-25T02:20:00.878452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def internal_influence(\n",
    "        self_position,\n",
    "        other_positions,\n",
    "        other_rotations,\n",
    "        sensing_radius = 1.5,\n",
    "        focus = 0.01,\n",
    "        noise = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate an influence vector for a single agent\n",
    "    based on the angular component of the Vicsek model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the position of the agent\n",
    "    other_positions : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the positions of the neighboring agents.\n",
    "    other_rotations : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the rotations of the neighboring agents.\n",
    "    sensing_radius : float\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    focus : float, optional\n",
    "        The dispersion of a von Mises distribution for rotational noise influenced by the neighbors.\n",
    "        The higher the value is, the less perturbation there would be.\n",
    "    noise: bool, optional\n",
    "        Whether the focus is interpreted as noise amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D unit vector representing the averaged influence direction with added noise.\n",
    "    \"\"\"\n",
    "\n",
    "    neighbor_rotations = []\n",
    "\n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "\n",
    "        if d <= sensing_radius and d > 0:\n",
    "            neighbor_rotations.append(other_rotations[i])\n",
    "\n",
    "    if len(neighbor_rotations) == 0:\n",
    "        return np.array([0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "    neighbor_rotations = np.array(neighbor_rotations)\n",
    "    averaged_rotation = np.sum(neighbor_rotations) / len(neighbor_rotations)\n",
    "\n",
    "    if noise:\n",
    "        deviation = (np.random.random() - 0.5) * focus\n",
    "    else:\n",
    "        deviation = np.random.vonmises(mu=0., kappa=4.) * focus\n",
    "    direction = averaged_rotation + deviation\n",
    "\n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32)\n",
    "\n",
    "    return v"
   ],
   "id": "1f7129d3d52d1784",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting everything together: combined influences\n",
    "\n",
    "The combined influences allow us to update the agents' positions and rotations together."
   ],
   "id": "d0eb58db671d160c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:03.525506Z",
     "start_time": "2025-06-25T02:20:03.324648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def count_neighbors(self_position, other_positions, sensing_radius = 1.5):\n",
    "    \"\"\"\n",
    "    Helper function that counts the number of neighbors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position   : np.ndarray of size (2)\n",
    "        The position of the agent itself\n",
    "    other_positions : np.ndarray of size (num_agents, 2)\n",
    "        The positions of all agents\n",
    "    sensing_radius  : float, default: 1.5\n",
    "        The sensing radius of the agent\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_neighbors   : int, default: 0\n",
    "        The number of neighbors within the agent's sensing radius.\n",
    "    \"\"\"\n",
    "\n",
    "    num_neighbors = 0\n",
    "\n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "\n",
    "        if d <= sensing_radius and d > 0:\n",
    "            num_neighbors += 1\n",
    "\n",
    "    return num_neighbors"
   ],
   "id": "49222407ea620c8f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:06.006079Z",
     "start_time": "2025-06-25T02:20:05.434818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_neighbors = count_neighbors(p[8], p)\n",
    "num_neighbors"
   ],
   "id": "77764dbd1777e36b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:06.286262Z",
     "start_time": "2025-06-25T02:20:06.069647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def combined_influences(\n",
    "    agent_positions: np.ndarray = None,\n",
    "    agent_rotations: np.ndarray = None,\n",
    "    beacon_positions: np.ndarray = None,\n",
    "    velocity: float = 1.0,\n",
    "    sensing_radius: float = 2.5,\n",
    "    dt: float = 0.1,\n",
    "    influence_weight: float = 0.5,\n",
    "    internal_focus: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the positions and orientations of a single agent\n",
    "    based on velocity and influence vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_positions : np.ndarray\n",
    "        Current positions of the agents.\n",
    "    agent_rotations : np.ndarray\n",
    "        Current orientations of the agents.\n",
    "    beacon_positions : np.ndarray\n",
    "        Positions of the beacons.\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    dt : float, optional\n",
    "        The time step for updating positions and orientations (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight of influence_vector1 in determining new orientations (default is 0.7).\n",
    "    external_focus : float, optional\n",
    "        Concentration of the agent's rotational noise influenced by the beacons\n",
    "    internal_focus : float, optional\n",
    "        Concentration of the agent's rotational noise influenced by the neighbors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        Updated positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "\n",
    "    assert (len(agent_positions) == len(agent_rotations))\n",
    "\n",
    "    num_agents = agent_positions.shape[0]\n",
    "    num_beacons = beacon_positions.shape[0]\n",
    "\n",
    "    # Create new numpy arrays for the updated agent positions and rotations\n",
    "    new_agent_positions = np.zeros((num_agents, 2))\n",
    "    new_agent_rotations = np.zeros((num_agents, ))\n",
    "    num_neighbors = np.zeros((num_agents, ))\n",
    "\n",
    "\n",
    "    for i in range(num_agents):\n",
    "\n",
    "        num_neighbors[i] = count_neighbors(agent_positions[i], agent_positions)\n",
    "\n",
    "        # Generate the ddm vector for the agent based on its closest beacon\n",
    "        distance_to_beacon = []\n",
    "\n",
    "        for b in range(num_beacons):\n",
    "            bx = beacon_positions[b, 0] - agent_positions[i, 0]\n",
    "            by = beacon_positions[b, 1] - agent_positions[i, 1]\n",
    "            distance_to_beacon.append((bx * bx + by * by) ** 0.5)\n",
    "\n",
    "        beacon_id = np.argmin(np.array(distance_to_beacon))\n",
    "\n",
    "        ddm_vector = external_influence(\n",
    "            agent_positions[i],\n",
    "            beacon_positions[beacon_id],\n",
    "            #focus=external_focus\n",
    "        )\n",
    "\n",
    "        # Generate the vicsek vector for the agent based on its neighbors (all agents)\n",
    "        vicsek_vector = internal_influence(\n",
    "            self_position=agent_positions[i],\n",
    "            other_positions=agent_positions,\n",
    "            other_rotations=agent_rotations,\n",
    "            sensing_radius=sensing_radius,\n",
    "            focus=internal_focus\n",
    "        )\n",
    "\n",
    "        # Update orientations based on two influence vectors\n",
    "        ddm_influence = np.arctan2(ddm_vector[1], ddm_vector[0])\n",
    "        vicsek_influence = np.arctan2(vicsek_vector[1], vicsek_vector[0])\n",
    "\n",
    "        # Combine influences to update orientations with different weights\n",
    "        new_agent_rotations[i] = agent_rotations[i] + (influence_weight * ddm_influence + (1 - influence_weight) * vicsek_influence) * dt\n",
    "\n",
    "        # Ensure orientations are within the range [0, 2*pi]\n",
    "        new_agent_rotations[i] = np.mod(new_agent_rotations[i], 2 * np.pi)\n",
    "\n",
    "        # Update positions based on current orientations\n",
    "        new_agent_positions[i, 0] = agent_positions[i, 0] + velocity * np.cos(new_agent_rotations[i].item()) * dt\n",
    "        new_agent_positions[i, 1] = agent_positions[i, 1] + velocity * np.sin(new_agent_rotations[i].item()) * dt\n",
    "\n",
    "        new_agent_positions[i] = bound_agent_position(new_agent_positions[i], room_size=room_size)\n",
    "\n",
    "    return new_agent_positions, new_agent_rotations, num_neighbors"
   ],
   "id": "8745190d61c56ce3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:13.430066Z",
     "start_time": "2025-06-25T02:20:10.895222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_positions, agent_rotations = initialize_agents(12, room_size=room_size)\n",
    "beacon_positions = initialize_beacons(num_beacons=2)\n",
    "new_agent_positions, new_agent_rotations, num_neighbors = combined_influences(agent_positions, agent_rotations, beacon_positions)"
   ],
   "id": "6a12b3b4383bdf92",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:13.664491Z",
     "start_time": "2025-06-25T02:20:13.463060Z"
    }
   },
   "cell_type": "code",
   "source": "np.concatenate([agent_positions, new_agent_positions], axis=1)",
   "id": "6226b2947f10bc12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.61377859,  2.22281265,  3.52952076,  2.27667003],\n",
       "       [ 1.20761299, -2.59568548,  1.19287595, -2.69459362],\n",
       "       [-1.12444496,  2.87083912, -1.03815461,  2.82030225],\n",
       "       [ 2.13848209, -4.43218756,  2.0493414 , -4.38686717],\n",
       "       [-2.93655777,  2.13259506, -2.84760465,  2.1782825 ],\n",
       "       [-0.68647909,  4.10777187, -0.78088372,  4.14075318],\n",
       "       [-0.3083849 , -4.50833416, -0.38664249, -4.44607864],\n",
       "       [ 2.3527112 ,  4.35702705,  2.44871147,  4.32902797],\n",
       "       [-1.31139159,  4.88965797, -1.36727366,  4.80672912],\n",
       "       [-3.70657372,  1.82863295, -3.6200449 ,  1.77850549],\n",
       "       [-2.04577971, -3.73958993, -2.0860792 , -3.64806971],\n",
       "       [-3.05455446, -1.41596496, -3.14467812, -1.45929771]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:16.350399Z",
     "start_time": "2025-06-25T02:20:16.109720Z"
    }
   },
   "cell_type": "code",
   "source": "np.vstack([agent_rotations, new_agent_rotations]).T",
   "id": "6d0bd9a3c2b38853",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.46227384, 2.57284912],\n",
       "       [4.31345463, 4.56447988],\n",
       "       [5.47024536, 5.75337616],\n",
       "       [2.66577649, 2.67123644],\n",
       "       [0.38510299, 0.47447819],\n",
       "       [2.71092057, 2.80548711],\n",
       "       [2.50084591, 2.46958911],\n",
       "       [5.70558214, 5.99940077],\n",
       "       [4.05608845, 4.11942594],\n",
       "       [5.61368799, 5.75811409],\n",
       "       [1.72099125, 1.98558325],\n",
       "       [3.47608089, 3.58977429]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:18.629179Z",
     "start_time": "2025-06-25T02:20:18.415096Z"
    }
   },
   "cell_type": "code",
   "source": "num_neighbors",
   "id": "ab7ef9d6df643aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 2., 0., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation Loop\n",
    "\n",
    "The update allows us to continuously simulate the agents' positions and rotations at a given interval"
   ],
   "id": "25bfa1803f2f644a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:20:22.066679Z",
     "start_time": "2025-06-25T02:20:21.808573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit(parallel=True)\n",
    "def simulator_fun(\n",
    "    batch_size: int = 1,\n",
    "    theta = None,\n",
    "    num_agents: int = 12,\n",
    "    num_beacons: int = 1,\n",
    "    room_size: tuple = (8, 10),\n",
    "    velocity: float = 1.0,\n",
    "    dt: float = 0.001,\n",
    "    influence_weight: float = 0.7,\n",
    "    sensing_radius: float = 10.0,\n",
    "    internal_focus: float = 0.1,\n",
    "    time_horizon: float = 30.\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the simulation and store the time series of positions and orientations of agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : np.ndarray\n",
    "        Prior parameters specifying the internal properties of the agents\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    num_beacons : int, optional\n",
    "        Number of beacons to generate (default is 1).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100).\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    dt : float, optional\n",
    "        The time step for the update (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight for influence_vector1 in determining new orientations (default is 0.7).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius for the Vicsek model (default is 10.0).\n",
    "    num_timesteps : int, optional\n",
    "        The number of steps to simulate (default is 100).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        The time series of positions and orientations of the agents.\n",
    "    \"\"\"\n",
    "\n",
    "    if theta is not None:\n",
    "        influence_weight = theta[0]\n",
    "        sensing_radius = theta[1]\n",
    "        velocity = theta[2]\n",
    "        #internal_focus = theta[3]\n",
    "\n",
    "\n",
    "    num_timesteps = int(time_horizon / dt)\n",
    "\n",
    "    # Apply radial bound with sigmoid transformation for the sensing radius\n",
    "    # (r_min, r_max) = (1., 5.)\n",
    "    # sensing_radius = r_min + (r_max - r_min) * (1. / (1. + np.exp(-sensing_radius)))\n",
    "\n",
    "    # Initialize arrays to store time series of positions and orientations\n",
    "    for b in range(batch_size):\n",
    "        positions = np.zeros((num_timesteps, num_agents, 2))\n",
    "        rotations = np.zeros((num_timesteps, num_agents, ))\n",
    "        neighbors = np.zeros((num_timesteps, num_agents, ))\n",
    "\n",
    "            # Initialize positions and orientations\n",
    "        initial_positions, initial_rotations = initialize_agents(num_agents, room_size=room_size)\n",
    "        positions[0] = initial_positions\n",
    "        rotations[0] = initial_rotations\n",
    "\n",
    "        # Initialize beacons\n",
    "        beacon_positions = initialize_beacons(num_beacons)\n",
    "\n",
    "        # Simulation loop\n",
    "        for t in range(1, num_timesteps):\n",
    "            ps, rs, num_neighbors = combined_influences(\n",
    "                agent_positions=positions[t-1],\n",
    "                agent_rotations=rotations[t-1],\n",
    "                beacon_positions=beacon_positions,\n",
    "                velocity=velocity,\n",
    "                sensing_radius=sensing_radius,\n",
    "                dt=dt,\n",
    "                influence_weight=influence_weight,\n",
    "                internal_focus=internal_focus\n",
    "            )\n",
    "\n",
    "            # Store positions and orientations for each time step\n",
    "            positions[t] = ps\n",
    "            rotations[t] = rs\n",
    "            neighbors[t] = num_neighbors\n",
    "\n",
    "        neighbors[0] = neighbors[1]\n",
    "\n",
    "        rotations = rotations[:,:,np.newaxis]\n",
    "        neighbors = neighbors[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "    return np.concatenate((positions, rotations, neighbors), axis=-1)"
   ],
   "id": "ffcbc6acb0544952",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:24:14.296234Z",
     "start_time": "2025-06-25T02:24:14.070363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TogetherFlowSimulator:\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_agents: int = 12,\n",
    "                 num_beacons: int = 1,\n",
    "                 room_size: tuple = (8, 10),\n",
    "                 dt: float = 0.001,\n",
    "                 internal_focus: float = 0.1,\n",
    "                 time_horizon: float = 30.\n",
    "                 ):\n",
    "        self.num_agents = num_agents\n",
    "        self.num_beacons = num_beacons\n",
    "        self.room_size = room_size\n",
    "        self.dt = dt\n",
    "        self.internal_focus = internal_focus\n",
    "        self.time_horizon = time_horizon\n",
    "\n",
    "\n",
    "    def sample(self, batch_shape: int | tuple = (1,)) -> dict[str, np.ndarray]:\n",
    "\n",
    "        batch_size = batch_shape[0]\n",
    "        thetas = []\n",
    "        samples = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            theta = complete_pooling_prior()\n",
    "            sim = simulator_fun(\n",
    "                theta=theta,\n",
    "                num_agents=self.num_agents,\n",
    "                num_beacons=self.num_beacons,\n",
    "                room_size=self.room_size,\n",
    "                dt=self.dt,\n",
    "                internal_focus=self.internal_focus,\n",
    "                time_horizon=self.time_horizon\n",
    "            )\n",
    "            thetas.append(theta)\n",
    "            samples.append(sim)\n",
    "\n",
    "        thetas = np.array(thetas)\n",
    "        samples = np.array(samples)\n",
    "\n",
    "        return dict(\n",
    "            w = thetas[:,0],\n",
    "            r = thetas[:,1],\n",
    "            v = thetas[:,2],\n",
    "            positions = samples[:,:,:,0:2],\n",
    "            rotations = samples[:,:,:,2],\n",
    "            neighbors = samples[:,:,:,3]\n",
    "        )"
   ],
   "id": "a3fd7c62de2ff278",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:24:15.551259Z",
     "start_time": "2025-06-25T02:24:15.351068Z"
    }
   },
   "cell_type": "code",
   "source": "simulator = TogetherFlowSimulator(num_agents=49)",
   "id": "77d5a1f3641a32af",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:24:39.460070Z",
     "start_time": "2025-06-25T02:24:17.453185Z"
    }
   },
   "cell_type": "code",
   "source": "test_sims = simulator.sample(batch_shape=(10,))",
   "id": "d023cd448fdc688",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:25:14.187898Z",
     "start_time": "2025-06-25T02:25:13.972275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(test_sims['w'].shape)\n",
    "print(test_sims['r'].shape)\n",
    "print(test_sims['v'].shape)\n",
    "print(test_sims['positions'].shape)\n",
    "print(test_sims['rotations'].shape)\n",
    "print(test_sims['neighbors'].shape)"
   ],
   "id": "41bfaf2c0c7a136c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10, 30000, 49, 2)\n",
      "(10, 30000, 49)\n",
      "(10, 30000, 49)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Priors",
   "id": "f581a8b8107de537"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adapter",
   "id": "c7d3e491282812d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:27:01.187875Z",
     "start_time": "2025-06-25T02:27:00.971345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .as_time_series([\"positions\", \"rotations\", \"neighbors\"])\n",
    "    .expand_dims(['rotations', 'neighbors'], axis=-1)\n",
    "    .expand_dims(['w', 'r', 'v'], axis=-1)\n",
    "    .concatenate(['w', 'r', 'v'], into=\"inference_variables\")\n",
    "    .concatenate([\"positions\", \"rotations\", \"neighbors\"], into=\"summary_variables\", axis=-1)\n",
    ")"
   ],
   "id": "69137094735b10b1",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:27:24.439253Z",
     "start_time": "2025-06-25T02:27:20.209693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adapted_simulator = TogetherFlowSimulator(num_agents=49)\n",
    "adapter_sim = adapter(adapted_simulator.sample(batch_shape=(2,)))"
   ],
   "id": "d452bff0a8f006f7",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:27:31.076262Z",
     "start_time": "2025-06-25T02:27:30.864976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(adapter_sim['summary_variables'].shape)\n",
    "print(adapter_sim['inference_variables'].shape)"
   ],
   "id": "94267ce51c15bc59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30000, 49, 4)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Approximator",
   "id": "bb6da22bb3c43d6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:56:04.599450Z",
     "start_time": "2025-06-25T02:56:04.228183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How do we go about the summary network, since HierarchicalNetwork has not been implemented yet?\n",
    "\n",
    "# Need to ask Stefan about this.\n",
    "summary_net = bf.networks.TimeSeriesTransformer()"
   ],
   "id": "a45ebbfd8f0a1a38",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:56:05.691917Z",
     "start_time": "2025-06-25T02:56:05.478173Z"
    }
   },
   "cell_type": "code",
   "source": "inference_net = bf.networks.FlowMatching()",
   "id": "e31c14fc18c97048",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:56:09.750629Z",
     "start_time": "2025-06-25T02:56:09.564617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = bf.workflows.BasicWorkflow(\n",
    "    simulator=adapted_simulator,\n",
    "    adapter=adapter,\n",
    "    inference_network=inference_net,\n",
    "    summary_network=summary_net,\n",
    ")"
   ],
   "id": "6a4a56474df53e0a",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:53:28.698665Z",
     "start_time": "2025-06-25T02:37:02.055362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = workflow.simulate((200,))\n",
    "test_set = workflow.simulate((10,))"
   ],
   "id": "291b97683c82f7ad",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T02:56:21.929058Z",
     "start_time": "2025-06-25T02:56:13.895627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = workflow.fit_offline(\n",
    "    data=train_set,\n",
    "    validation_set=test_set,\n",
    "    batch_size=32,\n",
    "    epochs=1\n",
    ")"
   ],
   "id": "65a6ecfd4c7bd774",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OfflineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling Time2Vec.call().\n\n\u001B[1m{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [32,30000,49,4] vs. shape[1] = [32,30000,8] [Op:ConcatV2] name: concat\u001B[0m\n\nArguments received by Time2Vec.call():\n  • x=tf.Tensor(shape=(32, 30000, 49, 4), dtype=float32)\n  • t=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[62], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mworkflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_offline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\workflows\\basic_workflow.py:722\u001B[0m, in \u001B[0;36mBasicWorkflow.fit_offline\u001B[1;34m(self, data, epochs, batch_size, keep_optimizer, validation_data, augmentations, **kwargs)\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;124;03mTrain the approximator offline using a fixed dataset. This approach will be faster than online training,\u001B[39;00m\n\u001B[0;32m    679\u001B[0m \u001B[38;5;124;03msince no computation time is spent in generating new data for each batch, but it assumes that simulations\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;124;03m    metric evolution over epochs.\u001B[39;00m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    720\u001B[0m dataset \u001B[38;5;241m=\u001B[39m OfflineDataset(data\u001B[38;5;241m=\u001B[39mdata, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, adapter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madapter, augmentations\u001B[38;5;241m=\u001B[39maugmentations)\n\u001B[1;32m--> 722\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(\n\u001B[0;32m    723\u001B[0m     dataset, epochs, strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monline\u001B[39m\u001B[38;5;124m\"\u001B[39m, keep_optimizer\u001B[38;5;241m=\u001B[39mkeep_optimizer, validation_data\u001B[38;5;241m=\u001B[39mvalidation_data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    724\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\workflows\\basic_workflow.py:954\u001B[0m, in \u001B[0;36mBasicWorkflow._fit\u001B[1;34m(self, dataset, epochs, strategy, keep_optimizer, validation_data, **kwargs)\u001B[0m\n\u001B[0;32m    951\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapproximator\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer, metrics\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetrics\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 954\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapproximator\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m    955\u001B[0m         dataset\u001B[38;5;241m=\u001B[39mdataset, epochs\u001B[38;5;241m=\u001B[39mepochs, validation_data\u001B[38;5;241m=\u001B[39mvalidation_data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    956\u001B[0m     )\n\u001B[0;32m    957\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_training_finished()\n\u001B[0;32m    958\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py:316\u001B[0m, in \u001B[0;36mContinuousApproximator.fit\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    265\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;124;03m    Trains the approximator on the provided dataset or on-demand data generated from the given simulator.\u001B[39;00m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;124;03m    If `dataset` is not provided, a dataset is built from the `simulator`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;124;03m        If both `dataset` and `simulator` are provided or neither is provided.\u001B[39;00m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, adapter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madapter)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\approximators\\approximator.py:137\u001B[0m, in \u001B[0;36mApproximator.fit\u001B[1;34m(self, dataset, simulator, **kwargs)\u001B[0m\n\u001B[0;32m    135\u001B[0m     mock_data \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mtree\u001B[38;5;241m.\u001B[39mmap_structure(keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mconvert_to_tensor, mock_data)\n\u001B[0;32m    136\u001B[0m     mock_data_shapes \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mtree\u001B[38;5;241m.\u001B[39mmap_structure(keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mshape, mock_data)\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_data_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(dataset\u001B[38;5;241m=\u001B[39mdataset, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\keras\\src\\layers\\layer.py:232\u001B[0m, in \u001B[0;36mLayer.__new__.<locals>.build_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_open_name_scope():\n\u001B[0;32m    231\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m current_path()\n\u001B[1;32m--> 232\u001B[0m     original_build_method(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;66;03m# Record build config.\u001B[39;00m\n\u001B[0;32m    234\u001B[0m signature \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(original_build_method)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py:80\u001B[0m, in \u001B[0;36mContinuousApproximator.build\u001B[1;34m(self, data_shapes)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummary_network \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummary_network\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[1;32m---> 80\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msummary_network\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_shapes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msummary_variables\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m     summary_outputs_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msummary_network\u001B[38;5;241m.\u001B[39mcompute_output_shape(data_shapes[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_variables\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     83\u001B[0m \u001B[38;5;66;03m# Compute inference_conditions_shape by combining original and summary outputs\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\keras\\src\\layers\\layer.py:232\u001B[0m, in \u001B[0;36mLayer.__new__.<locals>.build_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_open_name_scope():\n\u001B[0;32m    231\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m current_path()\n\u001B[1;32m--> 232\u001B[0m     original_build_method(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;66;03m# Record build config.\u001B[39;00m\n\u001B[0;32m    234\u001B[0m signature \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(original_build_method)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\utils\\decorators.py:95\u001B[0m, in \u001B[0;36margument_callback.<locals>.callback_wrapper.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     92\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(args)\n\u001B[0;32m     93\u001B[0m     args[argpos] \u001B[38;5;241m=\u001B[39m callback(args[argpos])\n\u001B[1;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\networks\\summary_network.py:18\u001B[0m, in \u001B[0;36mSummaryNetwork.build\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;129m@sanitize_input_shape\u001B[39m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_shape):\n\u001B[0;32m     17\u001B[0m     x \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mzeros(input_shape)\n\u001B[1;32m---> 18\u001B[0m     z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_distribution \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_distribution\u001B[38;5;241m.\u001B[39mbuild(keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mshape(z))\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\networks\\transformers\\time_series_transformer.py:140\u001B[0m, in \u001B[0;36mTimeSeriesTransformer.call\u001B[1;34m(self, input_sequence, training, **kwargs)\u001B[0m\n\u001B[0;32m    137\u001B[0m     inp \u001B[38;5;241m=\u001B[39m input_sequence\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_embedding:\n\u001B[1;32m--> 140\u001B[0m     inp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43minp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;66;03m# Apply self-attention blocks\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention_blocks:\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\networks\\embeddings\\time2vec.py:88\u001B[0m, in \u001B[0;36mTime2Vec.call\u001B[1;34m(self, x, t)\u001B[0m\n\u001B[0;32m     86\u001B[0m periodic \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39msin(t[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperiodic_weights[\u001B[38;5;28;01mNone\u001B[39;00m, :] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperiodic_biases[\u001B[38;5;28;01mNone\u001B[39;00m, :])\n\u001B[0;32m     87\u001B[0m emb \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mconcatenate([linear[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m], periodic], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Exception encountered when calling Time2Vec.call().\n\n\u001B[1m{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [32,30000,49,4] vs. shape[1] = [32,30000,8] [Op:ConcatV2] name: concat\u001B[0m\n\nArguments received by Time2Vec.call():\n  • x=tf.Tensor(shape=(32, 30000, 49, 4), dtype=float32)\n  • t=None"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plots = workflow.plot_default_diagnostics(\n",
    "\n",
    ")"
   ],
   "id": "9283779c089c873d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
