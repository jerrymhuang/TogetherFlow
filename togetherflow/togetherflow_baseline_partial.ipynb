{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Togetherflow: Partial Pooling\n",
    "**Emergent agent motion dynamics in immersive rooms**\n",
    "\n",
    "In this notebook, we implement Togetherflow, a computational cognitive model that characterizes the motion pattern of human agents in immersive rooms."
   ],
   "id": "ec5d25f2ecfd9f0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:24:29.354104Z",
     "start_time": "2025-05-01T21:24:29.230795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "94000e12f896fd20",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-01T21:24:30.136072Z",
     "start_time": "2025-05-01T21:24:29.415702Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from numba import njit\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:24:46.819386Z",
     "start_time": "2025-05-01T21:24:30.792400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import bayesflow as bf\n",
    "\n",
    "# from bayesflow.simulation import Prior, Simulator, GenerativeModel\n",
    "from bayesflow.simulation import TwoLevelPrior, Simulator, TwoLevelGenerativeModel\n",
    "\n",
    "from functools import partial"
   ],
   "id": "6f3ee90314c7f80a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gerald Wong\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Gerald Wong\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gerald Wong\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gerald Wong\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gerald Wong\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "C:\\Users\\Gerald Wong\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:27: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:05.309184Z",
     "start_time": "2025-05-01T21:25:03.166004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from priors import (\n",
    "    partial_pooling_hyper_prior, \n",
    "    partial_pooling_local_prior, \n",
    "    partial_pooling_shared_prior\n",
    ")\n",
    "from utils import count_neighbors"
   ],
   "id": "ea044d96a5ff9e08",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Generative Model Definition\n",
    "\n",
    "The movement of any agent $a = 1, ..., A$ is both related to: 1) its interaction with surrounding neighbors $i = 1, ..., I$, which we call *internal influence*, and 2) their motivation to the surrounding spatial objects $j = 1, ..., J$, which we call *external influence*. These influences are modulated by a stationary weight, $w_a$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a, t} = w_a \\theta_{a|j, t} + (1 - w_a) \\theta_{a|i, t}.\n",
    "\\end{equation}"
   ],
   "id": "a09afe3ad59c086c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta-Variables\n",
    "\n",
    "First, we define some meta-variables, such as the number of agents to simulate, the number of spatial beacons present in the environment, etc."
   ],
   "id": "95359faf1b874a3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:10.775674Z",
     "start_time": "2025-05-01T21:25:09.371543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_agents = 12\n",
    "num_beacons = 2\n",
    "room_size = (8., 10.)\n",
    "world_size = 25."
   ],
   "id": "412e662d0bd884a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperpriors and priors",
   "id": "e0042d5c7e8fb0b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:20.582256Z",
     "start_time": "2025-05-01T21:25:14.519496Z"
    }
   },
   "cell_type": "code",
   "source": "test_hypers = partial_pooling_hyper_prior()",
   "id": "a7a1cc751bf1f7e8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:29.592593Z",
     "start_time": "2025-05-01T21:25:20.693923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_locals = partial_pooling_local_prior(test_hypers)\n",
    "test_locals[:,0].shape"
   ],
   "id": "ca429d8569410f4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:33.904803Z",
     "start_time": "2025-05-01T21:25:29.789793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_shared = partial_pooling_shared_prior()\n",
    "test_shared.shape"
   ],
   "id": "891aad186d5217df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:38.864836Z",
     "start_time": "2025-05-01T21:25:34.048918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior = TwoLevelPrior(\n",
    "    hyper_prior_fun=partial_pooling_hyper_prior, \n",
    "    local_prior_fun=partial(partial_pooling_local_prior, num_agents=num_agents),\n",
    "    shared_prior_fun=partial_pooling_shared_prior\n",
    ")\n",
    "\n",
    "prior_sim = prior(batch_size=1)\n",
    "print(prior_sim['shared_parameters'].shape)\n",
    "print(prior_sim['local_parameters'].shape)\n",
    "print(prior_sim['hyper_parameters'].shape)"
   ],
   "id": "37a3707e6e33ac6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 12, 2)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:25:39.289156Z",
     "start_time": "2025-05-01T21:25:38.967422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "theta = (prior_sim['local_parameters'], prior_sim['shared_parameters'])\n",
    "theta"
   ],
   "id": "bfedf42ee2d2e187",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.22235642, 0.39541197],\n",
       "         [0.37234595, 0.848537  ],\n",
       "         [0.4780298 , 0.5286608 ],\n",
       "         [0.50385153, 0.5065906 ],\n",
       "         [0.68902504, 0.73930544],\n",
       "         [0.17884244, 0.46905306],\n",
       "         [0.5294097 , 0.69183105],\n",
       "         [0.3437501 , 0.5093107 ],\n",
       "         [0.59743595, 0.26365143],\n",
       "         [0.7471547 , 0.63524103],\n",
       "         [0.3290752 , 0.72246414],\n",
       "         [0.41547066, 0.5867914 ]]], dtype=float32),\n",
       " array([[2.7674232]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Agent Initialization\n",
    "First, we initialize the agents with a randomized position and orientation, both uniformly distributed."
   ],
   "id": "946c3a8ad7c1020b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:21:21.102506Z",
     "start_time": "2025-02-13T17:21:20.873136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_agents(\n",
    "    num_agents: int = 12, \n",
    "    room_size: tuple = (8., 10.),\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate random positions and orientations for agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100.0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        A tuple containing the positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate random positions within the boundary size centered at 0\n",
    "    x = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[0]\n",
    "    y = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[1]\n",
    "    positions = np.vstack((x, y)).T\n",
    "    \n",
    "    # Generate random orientations (angles in radians between 0 and 2*pi)\n",
    "    rotations = np.random.random(size=(num_agents, )).astype(np.float32) * np.pi * 2\n",
    "    \n",
    "    return positions.astype(np.float32), rotations.astype(np.float32)"
   ],
   "id": "4f404bcb3061544",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Beacon initialization\n",
    "\n",
    "To intrinsically motivate the agents, we need a set of virtual beacons that are populated within the environment. The beacons have a freer representation with only positions needed."
   ],
   "id": "c8523e5fa3d56cdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:21:21.806502Z",
     "start_time": "2025-02-13T17:21:21.589057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_beacons(\n",
    "        num_beacons = 10,\n",
    "        room_sensing_range = 50.\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Initialize beacons following a uniform distribution scaled to the room's sensing boundary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_beacons : int, default: 10\n",
    "        Number of beacons to initialize.\n",
    "    room_sensing_range : float, default: 50.0\n",
    "        Size of the environment for the generation of beacons.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    beacons      : np.ndarray of shape (num_beacons, 2)\n",
    "        Initial positions of the beacons. \n",
    "    \"\"\"\n",
    "    \n",
    "    beacons = (np.random.random(size=(num_beacons, 2)) - 0.5) * room_sensing_range\n",
    "    return beacons.astype(np.float32)"
   ],
   "id": "38b3585336753b1e",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## External Influence: drift-diffusion vector\n",
    "\n",
    "We want to compute the influence of agent movement direction within a single time step. For this, we specify our internal influence as a 2D drift diffusion model, where the agents are approach a spatial beacon within the room's boundary by reorienting its locomotive direction.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a|j, t} = \\theta_{a|j, t-1} + \\omega_a \\mathrm{d}t + \\mathrm{d}\\phi_t,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{d}\\mathbf{x}_{a|j, t} \n",
    "    &= v_{a|j}\\mathrm{d}t \\frac{\\mathbf{x}_{a|j}}{||\\mathbf{x}_{a|j}||} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t \\\\\n",
    "    &= v_{a}\\mathrm{d}t     \n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|j, t} \\\\\n",
    "        \\sin \\theta_{a|j, t}\n",
    "    \\end{bmatrix} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t,% \\sqrt{\\mathrm{d}t} Z_t.\n",
    "\\end{align}"
   ],
   "id": "abd398a2985b3af7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:21:23.444117Z",
     "start_time": "2025-02-13T17:21:23.228806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def external_influence( \n",
    "    agent_position,\n",
    "    target_position,\n",
    "    noise = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a drift-diffusion vector in 2D space for a single agent \n",
    "    based on a target location (in this case, the position of a beacon).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_position : np.ndarray\n",
    "        The position of the agent.\n",
    "    target_position : np.ndarray\n",
    "        The position of the target beacon.\n",
    "    noise : float, optional\n",
    "        The rate of diffusion, which determines the variability of the direction (default is 0.1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D vector representing the drift-diffusion process towards the target (beacon).\n",
    "    \"\"\"\n",
    "    # Calculate the angle towards the beacon (in radian)\n",
    "    target_angle = np.arctan2(\n",
    "        target_position[1] - agent_position[1], \n",
    "        target_position[0] - agent_position[0]\n",
    "    )\n",
    "    \n",
    "    # Generate a random direction with drift around the target angle\n",
    "    direction = np.random.vonmises(mu=target_angle, kappa=noise)\n",
    "    \n",
    "    # Convert the angle to a unit vector in 2D space\n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32)\n",
    "    \n",
    "    return v"
   ],
   "id": "baee136816ec7fd5",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Internal Influence: particle dynamics\n",
    "\n",
    "Its influence by a collective group of agents is modeled as a self-propelling particle system, as expressed in the Vicsek model:\n",
    "\n",
    "\\begin{align}\n",
    "    \\theta_{a|i, t} &= \\langle \\theta_{i, t}\\rangle_{|\\mathbf{x}_a - \\mathbf{x}_i| < r_a, i \\in I} + \\eta_{a,t-1}, \\\\\n",
    "    \\mathrm{d} \\mathbf{x}_{a|i,t} &= v_{a,t} \\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|i, t} \\\\\n",
    "        \\sin \\theta_{a|i, t}\n",
    "    \\end{bmatrix},\n",
    "\\end{align}"
   ],
   "id": "d993e6f6dfdb3038"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:21:25.104001Z",
     "start_time": "2025-02-13T17:21:24.900261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit \n",
    "def internal_influence(\n",
    "        self_position,\n",
    "        other_positions,\n",
    "        other_rotations,\n",
    "        sensing_radius = 1.5,\n",
    "        noise = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate an influence vector for a single agent \n",
    "    based on the angular component of the Vicsek model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the position of the agent\n",
    "    neighbor_positions : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the positions of the neighboring agents.\n",
    "    neighbor_rotations : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the rotations of the neighboring agents.\n",
    "    sensing_radius : float\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    noise : float, optional\n",
    "        The level of noise to add to the average direction (default is 0.1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D unit vector representing the averaged influence direction with added noise.\n",
    "    \"\"\"\n",
    "      \n",
    "    neighbor_rotations = []\n",
    "    \n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "        \n",
    "        if d <= sensing_radius and d > 0:\n",
    "            neighbor_rotations.append(other_rotations[i])\n",
    "            \n",
    "    if len(neighbor_rotations) == 0:\n",
    "        return np.array([0.0, 0.0], dtype=np.float32)\n",
    "    \n",
    "    neighbor_rotations = np.array(neighbor_rotations)\n",
    "    averaged_rotation = np.sum(neighbor_rotations) / len(neighbor_rotations)\n",
    "    \n",
    "    noise_rotation = (np.random.random() - 0.5) * 2 * noise\n",
    "    direction = averaged_rotation + noise_rotation\n",
    "    \n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32) \n",
    "    \n",
    "    return v"
   ],
   "id": "5e92d44292218f7f",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting everything together: combined influences\n",
    "\n",
    "The combined influences allow us to update the agents' positions and rotations together."
   ],
   "id": "13c0b15cd53302c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:28:33.325685Z",
     "start_time": "2025-02-13T17:28:33.101564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def combined_influences(\n",
    "    agent_positions: np.ndarray = None, \n",
    "    agent_rotations: np.ndarray = None,\n",
    "    beacon_positions: np.ndarray = None,\n",
    "    velocity: float | np.ndarray = 1.0, \n",
    "    sensing_radius: float = 2.5,\n",
    "    dt: float = 0.1, \n",
    "    influence_weight: float | np.ndarray = 0.5,\n",
    "    external_noise: float = 0.1,\n",
    "    internal_noise: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the positions and orientations of a single agent \n",
    "    based on velocity and influence vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_positions : np.ndarray\n",
    "        Current positions of the agents.\n",
    "    agent_rotations : np.ndarray\n",
    "        Current orientations of the agents.\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    dt : float, optional\n",
    "        The time step for updating positions and orientations (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight of influence_vector1 in determining new orientations (default is 0.7).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        Updated positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (len(agent_positions) == len(agent_rotations))\n",
    "    \n",
    "    num_agents = agent_positions.shape[0]\n",
    "    num_beacons = beacon_positions.shape[0]\n",
    "    \n",
    "    # Check if the shape of the weight is a float\n",
    "    if isinstance(influence_weight, float):\n",
    "        weights = np.array([influence_weight])\n",
    "        weights = np.broadcast_to(weights, shape=(num_agents, ))\n",
    "    else:\n",
    "        weights = influence_weight\n",
    "        \n",
    "    if isinstance(velocity, float):\n",
    "        v = np.array([velocity])\n",
    "        v = np.broadcast_to(v, shape=(num_agents, ))\n",
    "    else:\n",
    "        v = velocity\n",
    "    \n",
    "    # Create new numpy arrays for the updated agent positions and rotations\n",
    "    new_agent_positions = np.zeros((num_agents, 2))\n",
    "    new_agent_rotations = np.zeros((num_agents, ))\n",
    "    num_neighbors = np.zeros((num_agents, ))\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        # Generate the ddm vector for the agent based on its closest beacon\n",
    "        num_neighbors[i] = count_neighbors(agent_positions[i], agent_positions)\n",
    "\n",
    "        distance_to_beacon = []\n",
    "\n",
    "        for b in range(num_beacons):\n",
    "            bx = beacon_positions[b, 0] - agent_positions[i, 0]\n",
    "            by = beacon_positions[b, 1] - agent_positions[i, 1]\n",
    "            distance_to_beacon.append((bx * bx + by * by) ** 0.5)\n",
    "\n",
    "        beacon_id = np.argmin(np.array(distance_to_beacon))\n",
    "\n",
    "        ddm_vector = external_influence(\n",
    "            agent_positions[i], \n",
    "            beacon_positions[beacon_id],\n",
    "            noise=external_noise\n",
    "        )\n",
    "\n",
    "        # Generate the vicsek vector for the agent based on its neighbors (all agents)\n",
    "        vicsek_vector = internal_influence(\n",
    "            self_position=agent_positions[i],\n",
    "            other_positions=agent_positions,\n",
    "            other_rotations=agent_rotations,\n",
    "            sensing_radius=sensing_radius,\n",
    "            noise=internal_noise\n",
    "        )\n",
    "\n",
    "        # Update orientations based on two influence vectors\n",
    "        ddm_influence = np.arctan2(ddm_vector[1], ddm_vector[0])\n",
    "        vicsek_influence = np.arctan2(vicsek_vector[1], vicsek_vector[0])\n",
    "\n",
    "        # Combine influences to update orientations with different weights\n",
    "        new_agent_rotations[i] = agent_rotations[i] + (weights[i].item() * ddm_influence + (1 - weights[i].item()) * vicsek_influence) * dt\n",
    "\n",
    "        # Ensure orientations are within the range [0, 2*pi]\n",
    "        new_agent_rotations[i] = np.mod(new_agent_rotations[i], 2 * np.pi)\n",
    "\n",
    "        # Update positions based on current orientations\n",
    "        new_agent_positions[i, 0] = agent_positions[i, 0] + v[i].item() * np.cos(new_agent_rotations[i].item()) * dt\n",
    "        new_agent_positions[i, 1] = agent_positions[i, 1] + v[i].item() * np.sin(new_agent_rotations[i].item()) * dt\n",
    "\n",
    "    return new_agent_positions, new_agent_rotations, num_neighbors"
   ],
   "id": "ed773df5234411fa",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:28:36.754277Z",
     "start_time": "2025-02-13T17:28:35.532685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_positions, agent_rotations = initialize_agents(12, room_size=room_size)\n",
    "beacon_positions = initialize_beacons(num_beacons=2)\n",
    "new_agent_positions, new_agent_rotations, num_neighbors = combined_influences(agent_positions, agent_rotations, beacon_positions)"
   ],
   "id": "8fab2bd5934c0eec",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation Loop\n",
    "The update allows us to continuously simulate the agents' positions and rotations at a given interval"
   ],
   "id": "9fea369e1e7d1750"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:29:56.253788Z",
     "start_time": "2025-02-13T17:29:56.003570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def simulator_fun(\n",
    "    theta = None,\n",
    "    num_agents: int = 12, \n",
    "    num_beacons: int = 1,\n",
    "    room_size: tuple = (8, 10),\n",
    "    velocity: float = 1.0, \n",
    "    dt: float = 0.001, \n",
    "    influence_weight: float | np.ndarray = 0.7, \n",
    "    sensing_radius: float = 10.0,\n",
    "    external_noise: float = 0.1,\n",
    "    internal_noise: float = 0.1,\n",
    "    time_horizon: float = 30.\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the simulation and store the time series of positions and orientations of agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    num_beacons : int, optional\n",
    "        Number of beacons to generate (default is 1).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100).\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    dt : float, optional\n",
    "        The time step for the update (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight for influence_vector1 in determining new orientations (default is 0.7).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius for the Vicsek model (default is 10.0).\n",
    "    num_timesteps : int, optional\n",
    "        The number of steps to simulate (default is 100).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        The time series of positions and orientations of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if theta is not None: # Unpack tuples of local and shared priors\n",
    "        local_params = theta[0]\n",
    "        shared_params = theta[1]\n",
    "        \n",
    "        weights = local_params[:,0].copy()\n",
    "        velocity = local_params[:,1].copy()\n",
    "        sensing_radius = shared_params[0].item()\n",
    "        print(sensing_radius)\n",
    "        # velocity = shared_params[1].item()\n",
    "    else:\n",
    "        weights = np.array([influence_weight], dtype=np.float32)\n",
    "        weights = np.broadcast_to(weights, shape=(num_agents, ))\n",
    "        velocity = np.array([velocity], dtype=np.float32)\n",
    "        velocity = np.broadcast_to(velocity, shape=(num_agents, ))\n",
    "    \n",
    "    num_timesteps = int(time_horizon / dt)\n",
    "    \n",
    "    \n",
    "    # Initialize positions and orientations\n",
    "    initial_positions, initial_rotations = initialize_agents(num_agents, room_size=room_size)\n",
    "\n",
    "    # Initialize arrays to store time series of positions and orientations\n",
    "    positions = np.zeros((num_timesteps, num_agents, 2))\n",
    "    rotations = np.zeros((num_timesteps, num_agents, ))\n",
    "    neighbors = np.zeros((num_timesteps, num_agents, ))\n",
    "    positions[0] = initial_positions\n",
    "    rotations[0] = initial_rotations\n",
    "    \n",
    "    # Initialize beacons\n",
    "    beacon_positions = initialize_beacons(num_beacons)\n",
    "\n",
    "    # Simulation loop\n",
    "    for t in range(1, num_timesteps):\n",
    "        ps, rs, num_neighbors = combined_influences(\n",
    "            agent_positions=positions[t-1], \n",
    "            agent_rotations=rotations[t-1], \n",
    "            beacon_positions=beacon_positions, \n",
    "            velocity=velocity, \n",
    "            sensing_radius=sensing_radius, \n",
    "            dt=dt, \n",
    "            influence_weight=weights,\n",
    "            external_noise=external_noise,\n",
    "            internal_noise=internal_noise\n",
    "        )\n",
    "\n",
    "        # Store positions and orientations for each time step\n",
    "        positions[t] = ps\n",
    "        rotations[t] = rs\n",
    "        neighbors[t] = num_neighbors\n",
    "\n",
    "    neighbors[0] = neighbors[1]\n",
    "    \n",
    "    rotations = rotations[:,:,np.newaxis]\n",
    "    neighbors = neighbors[:,:,np.newaxis]\n",
    "\n",
    "    return np.concatenate((positions, rotations, neighbors), axis=-1)"
   ],
   "id": "24bd296bb797e8e0",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:29:58.977366Z",
     "start_time": "2025-02-13T17:29:56.776067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_hypers = partial_pooling_hyper_prior()\n",
    "test_locals = partial_pooling_local_prior(test_hypers)\n",
    "test_shared = partial_pooling_shared_prior()\n",
    "\n",
    "test_thetas = (test_locals, test_shared)\n",
    "test_sim = simulator_fun(test_thetas)"
   ],
   "id": "3f571730bf556b20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.305323362350464\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Partial Pooling Generative Model",
   "id": "28e47cb9af6f2f9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:28:58.171577Z",
     "start_time": "2025-02-13T17:28:57.953797Z"
    }
   },
   "cell_type": "code",
   "source": "prior",
   "id": "a97d0315438d146c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bayesflow.simulation.TwoLevelPrior at 0x1f4809d7850>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:28:59.202094Z",
     "start_time": "2025-02-13T17:28:58.930503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simulator = Simulator(simulator_fun=partial(simulator_fun, num_agents=num_agents, time_horizon=90, dt=1e-2))\n",
    "simulator"
   ],
   "id": "708755ac2eee7023",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bayesflow.simulation.Simulator at 0x1f48018f7c0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:29:02.341739Z",
     "start_time": "2025-02-13T17:29:00.114755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TwoLevelGenerativeModel(\n",
    "    prior=prior,\n",
    "    simulator=simulator,\n",
    "    simulator_is_batched=False,\n",
    "    name=\"TogetherFlowPP\"\n",
    ")"
   ],
   "id": "5dbbbaf629ea51ec",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't unbox heterogeneous list: array(float32, 2d, C) != array(float32, 1d, C)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTwoLevelGenerativeModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprior\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprior\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43msimulator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msimulator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43msimulator_is_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTogetherFlowPP\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\simulation.py:1181\u001B[0m, in \u001B[0;36mTwoLevelGenerativeModel.__init__\u001B[1;34m(self, prior, simulator, skip_test, simulator_is_batched, name)\u001B[0m\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m name\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_test:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\simulation.py:1234\u001B[0m, in \u001B[0;36mTwoLevelGenerativeModel._test\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1232\u001B[0m \u001B[38;5;66;03m# Use minimal n_sim > 1\u001B[39;00m\n\u001B[0;32m   1233\u001B[0m _n_sim \u001B[38;5;241m=\u001B[39m TwoLevelGenerativeModel\u001B[38;5;241m.\u001B[39m_N_SIM_TEST\n\u001B[1;32m-> 1234\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_n_sim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1235\u001B[0m \u001B[38;5;66;03m# Logger\u001B[39;00m\n\u001B[0;32m   1236\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger()\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\simulation.py:1196\u001B[0m, in \u001B[0;36mTwoLevelGenerativeModel.__call__\u001B[1;34m(self, batch_size, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m     sim_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator(prior_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocal_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_args\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\n\u001B[0;32m   1193\u001B[0m \u001B[38;5;66;03m# Case shared parameters - first input to simulator\u001B[39;00m\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;66;03m# is a tuple (local_parameters, shared_parameters)\u001B[39;00m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1196\u001B[0m     sim_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator(\n\u001B[0;32m   1197\u001B[0m         (prior_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocal_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]], prior_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshared_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]]),\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_args\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}),\n\u001B[0;32m   1199\u001B[0m     )\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;66;03m# Prepare and fill placeholder dict, starting from prior dict\u001B[39;00m\n\u001B[0;32m   1202\u001B[0m out_dict \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1203\u001B[0m     DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]: sim_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]],\n\u001B[0;32m   1204\u001B[0m     DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhyper_prior_draws\u001B[39m\u001B[38;5;124m\"\u001B[39m]: prior_out[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhyper_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1210\u001B[0m     DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprior_non_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]: prior_out\u001B[38;5;241m.\u001B[39mget(DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[0;32m   1211\u001B[0m }\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\simulation.py:598\u001B[0m, in \u001B[0;36mSimulator.__call__\u001B[1;34m(self, params, *args, **kwargs)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_batched:\n\u001B[0;32m    597\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_simulate_batched(params, out_dict, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 598\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_simulate_non_batched(params, out_dict, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\simulation.py:655\u001B[0m, in \u001B[0;36mSimulator._simulate_non_batched\u001B[1;34m(self, params, out_dict, *args, **kwargs)\u001B[0m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;66;03m# No context type\u001B[39;00m\n\u001B[0;32m    650\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    651\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    652\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    653\u001B[0m ):\n\u001B[0;32m    654\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[1;32m--> 655\u001B[0m         [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator(non_batched_params[b], \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(batch_size)]\n\u001B[0;32m    656\u001B[0m     )\n\u001B[0;32m    658\u001B[0m \u001B[38;5;66;03m# Only batchable context\u001B[39;00m\n\u001B[0;32m    659\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m out_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\simulation.py:655\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;66;03m# No context type\u001B[39;00m\n\u001B[0;32m    650\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    651\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    652\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    653\u001B[0m ):\n\u001B[0;32m    654\u001B[0m     out_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msim_data\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[1;32m--> 655\u001B[0m         [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimulator(non_batched_params[b], \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(batch_size)]\n\u001B[0;32m    656\u001B[0m     )\n\u001B[0;32m    658\u001B[0m \u001B[38;5;66;03m# Only batchable context\u001B[39;00m\n\u001B[0;32m    659\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m out_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon_batchable_context\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mTypeError\u001B[0m: can't unbox heterogeneous list: array(float32, 2d, C) != array(float32, 1d, C)"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:23:45.948121Z",
     "start_time": "2025-02-12T14:23:45.648077Z"
    }
   },
   "cell_type": "code",
   "source": "model(1)",
   "id": "69c8bbe25bc7bdbc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sim_data': array([[[[  -0.90284514,   -3.09879446,    1.83738256,    0.        ],\n",
       "          [  -1.20625234,    2.14825916,    6.00437212,    1.        ],\n",
       "          [   1.21305943,   -2.84071708,    1.14106202,    0.        ],\n",
       "          ...,\n",
       "          [   0.74777031,    4.08488226,    3.18753457,    1.        ],\n",
       "          [  -2.67125106,    0.03029108,    4.53164864,    0.        ],\n",
       "          [  -0.12742233,    3.49880981,    5.19029808,    1.        ]],\n",
       " \n",
       "         [[  -0.91229083,   -3.0653987 ,    1.84643754,    0.        ],\n",
       "          [  -1.17283158,    2.13890228,    6.0102024 ,    1.        ],\n",
       "          [   1.2274948 ,   -2.80915574,    1.14182591,    0.        ],\n",
       "          ...,\n",
       "          [   0.71308037,    4.08383053,    3.17190146,    1.        ],\n",
       "          [  -2.67711383,   -0.00391602,    4.54264771,    0.        ],\n",
       "          [  -0.11094568,    3.46826447,    5.20707011,    1.        ]],\n",
       " \n",
       "         [[  -0.922293  ,   -3.03216536,    1.86314092,    0.        ],\n",
       "          [  -1.13955003,    2.12906175,    5.99570101,    1.        ],\n",
       "          [   1.24204118,   -2.77764542,    1.13830614,    0.        ],\n",
       "          ...,\n",
       "          [   0.67839461,    4.0826492 ,    3.17563756,    1.        ],\n",
       "          [  -2.68349408,   -0.03803039,    4.52749956,    0.        ],\n",
       "          [  -0.09497161,    3.43745332,    5.1906882 ,    1.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  20.00827792,   -0.33379351,    3.84732253,    0.        ],\n",
       "          [ 277.55707618,   -8.69405893,    6.00565103,    0.        ],\n",
       "          [ 175.65163795,   71.12102757,    5.06825628,    0.        ],\n",
       "          ...,\n",
       "          [  51.05835563, -126.66811373,    1.27781535,    0.        ],\n",
       "          [ 221.40619729,   49.67485813,    5.61655069,    0.        ],\n",
       "          [ 250.67015043, -129.12452355,    0.46592581,    0.        ]],\n",
       " \n",
       "         [[  19.98157037,   -0.35595665,    3.83426936,    0.        ],\n",
       "          [ 277.5903406 ,   -8.70395723,    5.99396473,    0.        ],\n",
       "          [ 175.66319684,   71.08830311,    5.05192845,    0.        ],\n",
       "          ...,\n",
       "          [  51.06796923, -126.63476592,    1.29012379,    0.        ],\n",
       "          [ 221.43316655,   49.6530142 ,    5.60240249,    0.        ],\n",
       "          [ 250.70081246, -129.10826507,    0.48755228,    0.        ]],\n",
       " \n",
       "         [[  19.95491785,   -0.37818594,    3.83674808,    0.        ],\n",
       "          [ 277.62375131,   -8.71334991,    6.00913104,    0.        ],\n",
       "          [ 175.67459344,   71.05552178,    5.04697337,    0.        ],\n",
       "          ...,\n",
       "          [  51.07741139, -126.60136916,    1.29526073,    0.        ],\n",
       "          [ 221.45988247,   49.63086116,    5.59088691,    0.        ],\n",
       "          [ 250.73176666, -129.09257   ,    0.46926513,    0.        ]]]]),\n",
       " 'hyper_prior_draws': array([[4.626161 , 4.6691165]], dtype=float32),\n",
       " 'local_prior_draws': array([[0.6384266 , 0.52566665, 0.5420934 , 0.57009935, 0.5100301 ,\n",
       "         0.6912459 , 0.33950204, 0.47090298, 0.71448344, 0.5582623 ,\n",
       "         0.5935771 , 0.71473944]], dtype=float32),\n",
       " 'shared_prior_draws': array([[0.47111434, 3.4705877 ]], dtype=float32),\n",
       " 'sim_batchable_context': None,\n",
       " 'sim_non_batchable_context': None,\n",
       " 'prior_batchable_context': None,\n",
       " 'prior_non_batchable_context': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configurator",
   "id": "5093cdc36301f686"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:04:32.784742Z",
     "start_time": "2025-02-12T16:04:32.569423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configurator(input_dict: dict = None, transpose: bool = True):\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    output_dict[\"hyper_parameters\"] = input_dict[\"hyper_prior_draws\"].astype(np.float32, copy=False)\n",
    "    output_dict[\"local_parameters\"] = input_dict[\"local_prior_draws\"].astype(np.float32, copy=False)\n",
    "    output_dict[\"shared_parameters\"] = input_dict[\"shared_prior_draws\"].astype(np.float32, copy=False)\n",
    "    \n",
    "    # output_dict['sim_data'] = input_dict['sim_data']\n",
    "    \n",
    "    x = input_dict['sim_data'] / 10. \n",
    "    \n",
    "    if transpose:\n",
    "        x = np.moveaxis(x, 2, 1)[:, :, ::10, :]\n",
    "    else:\n",
    "        x = x[:, ::10, :, :]\n",
    "    \n",
    "    output_dict['summary_conditions'] = x.astype(np.float32, copy=False)\n",
    "    \n",
    "    return output_dict"
   ],
   "id": "57ed31f6830c39a6",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:04:34.376111Z",
     "start_time": "2025-02-12T16:04:33.540756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sim = model(5)\n",
    "out = configurator(sim)\n",
    "print(out['hyper_parameters'].shape)\n",
    "print(out['local_parameters'].shape)\n",
    "print(out['shared_parameters'].shape)\n",
    "print(out['summary_conditions'].shape)"
   ],
   "id": "d140299ec319b60c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "(5, 12)\n",
      "(5, 2)\n",
      "(5, 12, 900, 4)\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:09:42.187137Z",
     "start_time": "2025-02-12T16:09:41.807494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sim_hypers = tf.expand_dims(out['hyper_parameters'], 1)\n",
    "sim_hypers.shape"
   ],
   "id": "4995569ccf7aec7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 1, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hyper_conds = tf.tile(sim_hypers, [1, ])",
   "id": "f9977484cc3e8211"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:04:36.840947Z",
     "start_time": "2025-02-12T16:04:36.641078Z"
    }
   },
   "cell_type": "code",
   "source": "np.concatenate((out['local_parameters'], out['shared_parameters']), axis=-1)",
   "id": "1dc73aac4df49f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23141518, 0.02111889, 0.59030426, 0.02887834, 0.03028643,\n",
       "        0.26018226, 0.14625818, 0.29388615, 0.20256765, 0.20335384,\n",
       "        0.5750765 , 0.76530796, 0.36781076, 0.66003245],\n",
       "       [0.5066908 , 0.62286305, 0.3455291 , 0.30625427, 0.30888247,\n",
       "        0.5415735 , 0.8366986 , 0.3545949 , 0.30730695, 0.3149403 ,\n",
       "        0.2902986 , 0.40779418, 0.52978015, 3.3542616 ],\n",
       "       [0.35411188, 0.26319456, 0.5319078 , 0.6459103 , 0.3082867 ,\n",
       "        0.27793127, 0.20587584, 0.33567524, 0.06449239, 0.6091584 ,\n",
       "        0.41421542, 0.88799334, 0.04171411, 1.6557722 ],\n",
       "       [0.88382584, 0.9118702 , 0.7897539 , 0.8742594 , 0.5766562 ,\n",
       "        0.6276899 , 0.61687464, 0.29104984, 0.7201095 , 0.6491535 ,\n",
       "        0.9042915 , 0.89950514, 0.22838576, 2.1769125 ],\n",
       "       [0.85125655, 0.38041604, 0.74315745, 0.4893667 , 0.5871509 ,\n",
       "        0.51728773, 0.26759735, 0.62661034, 0.6096641 , 0.65441877,\n",
       "        0.2824899 , 0.44146028, 0.27614957, 2.0867538 ]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neural Approximator\n",
    "\n",
    "How many parameters are there? We have:\n",
    "\n",
    "- Hyperparameters: $\\alpha_w$, $\\beta_w$;\n",
    "- Local parameters: $w_a$, one for each agent;\n",
    "- Shared parameters: $r$, and $v$."
   ],
   "id": "628478544ffec3d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:44:39.366074Z",
     "start_time": "2025-02-12T17:44:38.294947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HierarchicalSummaryNetwork(tf.keras.Model):\n",
    "    def __init__(self, num_agents):\n",
    "        super().__init__()\n",
    "        self.num_agents = num_agents\n",
    "        self.agent_encoder = tf.keras.layers.TimeDistributed(\n",
    "            tf.keras.layers.LSTM(units=256, return_sequences=False)\n",
    "        )  # Encodes each agent's time series\n",
    "        \n",
    "        self.set_transformer = bf.networks.SetTransformer(\n",
    "            num_inducing_points=None, input_dim=256, summary_dim=32\n",
    "        )  # Aggregates agent embeddings\n",
    "\n",
    "        self.global_dense = tf.keras.layers.Dense(4, activation='linear')  # 4 global params\n",
    "        self.local_dense = tf.keras.layers.Dense(num_agents, activation='linear')  # Agent-specific params\n",
    "\n",
    "    def call(self, inputs, return_all=False):\n",
    "        \"\"\"\n",
    "        Inputs: (num_batches, num_agents, num_timesteps, num_features)\n",
    "        Outputs: (global_params, local_params), log_det_jacobian\n",
    "        \"\"\"\n",
    "        # Step 1: Encode agent-level time series\n",
    "        agent_representations = self.agent_encoder(inputs)  # (num_batches, num_agents, 256)\n",
    "        print(agent_representations.shape)\n",
    "\n",
    "        # Step 2: Aggregate across agents\n",
    "        global_summary = self.set_transformer(agent_representations)  # (num_batches, 32)\n",
    "        print(global_summary.shape)\n",
    "        \n",
    "        # Step 3: Predict parameters\n",
    "        global_params = self.global_dense(global_summary)  # (num_batches, 4)\n",
    "        local_params = self.local_dense(global_summary)  # (num_batches, num_agents)\n",
    "        \n",
    "        # Concatenate\n",
    "        params = tf.concat([global_params, local_params], axis=-1)\n",
    "        params = tf.expand_dims(params, axis=-1)\n",
    "        \n",
    "        # (num_batches, num_agents, 1) ensures per-agent conditioning works correctly\n",
    "        \n",
    "        # Step 5: Return correctly formatted outputs\n",
    "        if return_all:\n",
    "            return params, global_summary\n",
    "        else:\n",
    "            return params, 0.0  # Placeholder for log-det Jacobian"
   ],
   "id": "40e865fdce9311a4",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:18:58.024544Z",
     "start_time": "2025-02-12T16:18:57.800286Z"
    }
   },
   "cell_type": "code",
   "source": "out[]",
   "id": "e5efcec9e8366a21",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2289712505.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[128], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    out[]\u001B[0m\n\u001B[1;37m        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:44:45.403879Z",
     "start_time": "2025-02-12T17:44:43.065686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hierarchical_summary_net = HierarchicalSummaryNetwork(num_agents=num_agents)\n",
    "local_summaries, global_summaries = hierarchical_summary_net(out['summary_conditions'], return_all=True)\n",
    "print(local_summaries.shape, global_summaries.shape)"
   ],
   "id": "bef5c6a7d0a232ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 12, 256)\n",
      "(5, 32)\n",
      "(5, 16, 1) (5, 32)\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:44:48.937204Z",
     "start_time": "2025-02-12T17:44:48.690200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_locals = tf.shape(local_summaries)[1]\n",
    "num_locals"
   ],
   "id": "73d08d4da62d3aa7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=16>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:44:49.735719Z",
     "start_time": "2025-02-12T17:44:49.534922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyper_conds = tf.tile(sim_hypers, [1, num_locals, 1])\n",
    "hyper_conds.shape"
   ],
   "id": "764ac5a1f8560d8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 16, 2])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:45:41.503441Z",
     "start_time": "2025-02-12T17:45:41.301247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local_summaries = tf.concat([local_summaries, hyper_conds], axis=-1)\n",
    "local_summaries.shape"
   ],
   "id": "465a4b84a8d6c4bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 16, 5])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T16:05:08.460686Z",
     "start_time": "2025-02-12T16:05:06.326393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summary_net = bf.summary_networks.HierarchicalNetwork([\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.LSTM(units=256)),\n",
    "    bf.networks.SetTransformer(num_inducing_points=None, input_dim=256, summary_dim=16),\n",
    "    tf.keras.layers.Dense(16, activation='relu'), \n",
    "    tf.keras.layers.Dense(4, activation='linear')\n",
    "])\n",
    "\n",
    "summaries = summary_net(out[\"summary_conditions\"])"
   ],
   "id": "80c1c7eefc1efb3",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T15:50:37.254633Z",
     "start_time": "2025-02-12T15:50:36.494359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq_net = tf.keras.layers.TimeDistributed(bf.networks.SequenceNetwork(summary_dim=16))\n",
    "seq_net.build((None, None, None, 4))\n",
    "naive_summary_net = bf.summary_networks.HierarchicalNetwork(\n",
    "    [seq_net, bf.summary_networks.DeepSet(summary_dim=128)]\n",
    ")"
   ],
   "id": "8cd50623cf12998f",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:46:20.551851Z",
     "start_time": "2025-02-12T17:46:19.996151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local_inference_net = bf.inference_networks.InvertibleNetwork(\n",
    "    num_params=1,\n",
    "    num_coupling_layers=6,\n",
    "    coupling_design=\"spline\",\n",
    "    coupling_settings={\n",
    "        'units': 128,\n",
    "        'activation': 'swish',\n",
    "        'kernel_regularizer': None,\n",
    "        'dropout_prob': 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "global_inference_net = bf.inference_networks.InvertibleNetwork(\n",
    "    num_params=4, \n",
    "    num_coupling_layers=6,\n",
    "    coupling_design=\"spline\",\n",
    "    coupling_settings={\n",
    "        'units': 128,\n",
    "        'activation': 'swish',\n",
    "        'kernel_regularizer': None,\n",
    "        'dropout_prob': 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "local_amortizer = bf.amortizers.AmortizedPosterior(\n",
    "    inference_net=local_inference_net\n",
    ")\n",
    "\n",
    "global_amortizer = bf.amortizers.AmortizedPosterior(\n",
    "    inference_net=global_inference_net\n",
    ")\n",
    "\n",
    "amortizer = bf.amortizers.TwoLevelAmortizedPosterior(\n",
    "    summary_net=hierarchical_summary_net,\n",
    "    local_amortizer=local_amortizer,\n",
    "    global_amortizer=global_amortizer\n",
    ")"
   ],
   "id": "79e603ae939b5335",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Online Training",
   "id": "327f0dc4d8ecd531"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:46:25.466523Z",
     "start_time": "2025-02-12T17:46:23.269442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = bf.trainers.Trainer(\n",
    "    amortizer=amortizer,\n",
    "    generative_model=model,\n",
    "    configurator=configurator,\n",
    "    checkpoint_path=\"checkpoints/partial1\"\n",
    ")"
   ],
   "id": "cd2d7e3ef7c83c1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12, 256)\n",
      "(2, 32)\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "Could not carry out computations of generative_model ->configurator -> amortizer -> loss! Error trace:\n Exception encountered when calling layer 'dense_coupling_net_384' (type DenseCouplingNet).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2,1] vs. shape[1] = [2,16,5] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'dense_coupling_net_384' (type DenseCouplingNet):\n   target=tf.Tensor(shape=(2, 1), dtype=float32)\n   condition=tf.Tensor(shape=(2, 16, 5), dtype=float32)\n   kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:1315\u001B[0m, in \u001B[0;36mTrainer._check_consistency\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1314\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPerforming a consistency check with provided components...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1315\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mamortizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfigurator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerative_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_n_sim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1316\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\amortizers.py:1085\u001B[0m, in \u001B[0;36mTwoLevelAmortizedPosterior.compute_loss\u001B[1;34m(self, input_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1084\u001B[0m local_inputs, global_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_inputs(input_dict, local_summaries, global_summaries)\n\u001B[1;32m-> 1085\u001B[0m local_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_amortizer\u001B[38;5;241m.\u001B[39mcompute_loss(local_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1086\u001B[0m global_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_amortizer\u001B[38;5;241m.\u001B[39mcompute_loss(global_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\amortizers.py:208\u001B[0m, in \u001B[0;36mAmortizedPosterior.compute_loss\u001B[1;34m(self, input_dict, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# Get amortizer outputs\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m net_out, sum_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(input_dict, return_summary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    209\u001B[0m z, log_det_J \u001B[38;5;241m=\u001B[39m net_out\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\amortizers.py:180\u001B[0m, in \u001B[0;36mAmortizedPosterior.call\u001B[1;34m(self, input_dict, return_summary, **kwargs)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;66;03m# Compute output of inference net\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m net_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_net(input_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]], full_cond, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;66;03m# Return summary outputs or not, depending on parameter\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\inference_networks.py:178\u001B[0m, in \u001B[0;36mInvertibleNetwork.call\u001B[1;34m(self, targets, condition, inverse, **kwargs)\u001B[0m\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minverse(targets, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(targets, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\inference_networks.py:215\u001B[0m, in \u001B[0;36mInvertibleNetwork.forward\u001B[1;34m(self, targets, condition, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoupling_layers:\n\u001B[1;32m--> 215\u001B[0m     z, log_det_J \u001B[38;5;241m=\u001B[39m layer(z, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    216\u001B[0m     log_det_Js\u001B[38;5;241m.\u001B[39mappend(log_det_J)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:612\u001B[0m, in \u001B[0;36mCouplingLayer.call\u001B[1;34m(self, target_or_z, condition, inverse, **kwargs)\u001B[0m\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inverse:\n\u001B[1;32m--> 612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(target_or_z, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minverse(target_or_z, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:648\u001B[0m, in \u001B[0;36mCouplingLayer.forward\u001B[1;34m(self, target, condition, **kwargs)\u001B[0m\n\u001B[0;32m    647\u001B[0m \u001B[38;5;66;03m# Pass through coupling layer\u001B[39;00m\n\u001B[1;32m--> 648\u001B[0m latent, log_det_J_c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(target, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    649\u001B[0m log_det_Js \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m log_det_J_c\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:695\u001B[0m, in \u001B[0;36mCouplingLayer._forward\u001B[1;34m(self, target, condition, **kwargs)\u001B[0m\n\u001B[0;32m    694\u001B[0m u1, u2 \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39msplit(target, [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim_out1, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim_out2], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 695\u001B[0m v1, log_det_J1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet1(u1, u2, condition, inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    696\u001B[0m v2, log_det_J2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet2(u2, v1, condition, inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:251\u001B[0m, in \u001B[0;36mSplineCoupling.call\u001B[1;34m(self, split1, split2, condition, inverse, **kwargs)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inverse:\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(split1, split2, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inverse(split1, split2, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:273\u001B[0m, in \u001B[0;36mSplineCoupling._forward\u001B[1;34m(self, u1, u2, condition, **kwargs)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Performs a forward pass through the spline coupling layer. Used internally by the instance.\u001B[39;00m\n\u001B[0;32m    256\u001B[0m \n\u001B[0;32m    257\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;124;03m    The transformed input and the corresponding Jacobian of the transformation.\u001B[39;00m\n\u001B[0;32m    271\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 273\u001B[0m spline_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet(u2, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    274\u001B[0m spline_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_semantic_spline_parameters(spline_params)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\helper_networks.py:119\u001B[0m, in \u001B[0;36mDenseCouplingNet.call\u001B[1;34m(self, target, condition, **kwargs)\u001B[0m\n\u001B[0;32m    118\u001B[0m     condition \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mtile(condition, [\u001B[38;5;241m1\u001B[39m, shape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m--> 119\u001B[0m inp \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcondition\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(inp, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Exception encountered when calling layer 'dense_coupling_net_384' (type DenseCouplingNet).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2,1] vs. shape[1] = [2,16,5] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'dense_coupling_net_384' (type DenseCouplingNet):\n   target=tf.Tensor(shape=(2, 1), dtype=float32)\n   condition=tf.Tensor(shape=(2, 16, 5), dtype=float32)\n   kwargs={'training': 'None'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConfigurationError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[145], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mbf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamortizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamortizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerative_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfigurator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfigurator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcheckpoints/partial1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:220\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, amortizer, generative_model, configurator, checkpoint_path, max_to_keep, default_lr, skip_checks, memory, **kwargs)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;66;03m# Perform a sanity check with provided components\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_checks:\n\u001B[1;32m--> 220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_consistency\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:1318\u001B[0m, in \u001B[0;36mTrainer._check_consistency\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1316\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 1318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConfigurationError(\n\u001B[0;32m   1319\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not carry out computations of generative_model ->\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1320\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurator -> amortizer -> loss! Error trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1321\u001B[0m     )\n",
      "\u001B[1;31mConfigurationError\u001B[0m: Could not carry out computations of generative_model ->configurator -> amortizer -> loss! Error trace:\n Exception encountered when calling layer 'dense_coupling_net_384' (type DenseCouplingNet).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2,1] vs. shape[1] = [2,16,5] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'dense_coupling_net_384' (type DenseCouplingNet):\n   target=tf.Tensor(shape=(2, 1), dtype=float32)\n   condition=tf.Tensor(shape=(2, 16, 5), dtype=float32)\n   kwargs={'training': 'None'}"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "history = trainer.train_online(epochs=3, batch_size=32, iterations_per_epoch=500)",
   "id": "4a3187268a42a566"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8e205ccddb9b6ad8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Diagnostics",
   "id": "7b3f27b007c012f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "validation_sim = model(400)\n",
    "validation_configured = configurator(validation_sim)\n",
    "\n",
    "validation_configured[\"parameters\"]"
   ],
   "id": "412c0d878cc0df88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "post_samples = amortizer.sample(validation_configured, n_samples=1000)\n",
    "prior_samples = validation_configured[\"parameters\"]"
   ],
   "id": "907d01b78fe4463b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.set(rc={'axes.facecolor':'#FFFFFF00', 'figure.facecolor':'#FFFFFF00'})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "g = bf.diagnostics.plot_recovery(\n",
    "    post_samples=post_samples, \n",
    "    prior_samples=prior_samples, \n",
    "    param_names=param_names,\n",
    "    color=\"#4E2A84\"\n",
    ")"
   ],
   "id": "5725e4cbebdadde4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "c = bf.diagnostics.plot_z_score_contraction(post_samples=post_samples, prior_samples=prior_samples, param_names=param_names)",
   "id": "a3878000c0e66a46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "h = bf.diagnostics.plot_sbc_histograms(post_samples=post_samples, prior_samples=prior_samples, param_names=param_names, num_bins=10)",
   "id": "643f7dad757ff5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "e = bf.diagnostics.plot_sbc_ecdf(\n",
    "    post_samples=post_samples, \n",
    "    prior_samples=prior_samples, \n",
    "    param_names=param_names, \n",
    "    difference=True,\n",
    "    rank_ecdf_color=\"#4E2A84\"    \n",
    ")"
   ],
   "id": "be937b60c66bfddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "d = bf.diagnostics.plot_posterior_2d(posterior_draws=post_samples[1], prior_draws=prior_samples, param_names=param_names)",
   "id": "7028838ca96baada"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
