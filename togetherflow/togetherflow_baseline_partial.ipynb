{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Togetherflow: Partial Pooling\n",
    "**Emergent agent motion dynamics in immersive rooms**\n",
    "\n",
    "In this notebook, we implement Togetherflow, a computational cognitive model that characterizes the motion pattern of human agents in immersive rooms."
   ],
   "id": "ec5d25f2ecfd9f0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T15:10:30.639737Z",
     "start_time": "2025-02-06T15:10:30.548396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "94000e12f896fd20",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-06T15:13:47.073981Z",
     "start_time": "2025-02-06T15:13:46.661016Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from numba import njit\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:34:41.453244Z",
     "start_time": "2025-02-06T22:34:41.249635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import bayesflow as bf\n",
    "\n",
    "# from bayesflow.simulation import Prior, Simulator, GenerativeModel\n",
    "from bayesflow.simulation import TwoLevelPrior, Simulator, TwoLevelGenerativeModel\n",
    "\n",
    "from functools import partial"
   ],
   "id": "6f3ee90314c7f80a",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:40:59.217898Z",
     "start_time": "2025-02-06T22:40:58.987948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from priors import (\n",
    "    partial_pooling_hyper_prior, \n",
    "    partial_pooling_local_prior, \n",
    "    partial_pooling_shared_prior\n",
    ")\n",
    "from utils import count_neighbors"
   ],
   "id": "ea044d96a5ff9e08",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Generative Model Definition\n",
    "\n",
    "The movement of any agent $a = 1, ..., A$ is both related to: 1) its interaction with surrounding neighbors $i = 1, ..., I$, which we call *internal influence*, and 2) their motivation to the surrounding spatial objects $j = 1, ..., J$, which we call *external influence*. These influences are modulated by a stationary weight, $w_a$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a, t} = w_a \\theta_{a|j, t} + (1 - w_a) \\theta_{a|i, t}.\n",
    "\\end{equation}"
   ],
   "id": "a09afe3ad59c086c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Meta-Variables\n",
    "\n",
    "First, we define some meta-variables, such as the number of agents to simulate, the number of spatial beacons present in the environment, etc."
   ],
   "id": "95359faf1b874a3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:37:25.120894Z",
     "start_time": "2025-02-06T22:37:24.910433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_agents = 12\n",
    "num_beacons = 2\n",
    "room_size = (8., 10.)\n",
    "world_size = 25."
   ],
   "id": "412e662d0bd884a",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperpriors and priors",
   "id": "e0042d5c7e8fb0b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:03.783549Z",
     "start_time": "2025-02-06T22:41:02.873978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior = TwoLevelPrior(\n",
    "    hyper_prior_fun=partial_pooling_hyper_prior, \n",
    "    local_prior_fun=partial_pooling_local_prior,\n",
    "    shared_prior_fun=partial_pooling_shared_prior\n",
    ")\n",
    "\n",
    "prior_sim = prior(batch_size=1)\n",
    "print(prior_sim['shared_parameters'].shape)\n",
    "print(prior_sim['local_parameters'].shape)\n",
    "print(prior_sim['hyper_parameters'].shape)"
   ],
   "id": "37a3707e6e33ac6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 1)\n",
      "(1, 12, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:37:31.778542Z",
     "start_time": "2025-02-06T22:37:31.562586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "theta = (prior_sim['local_parameters'], prior_sim['shared_parameters'])\n",
    "theta[1].shape"
   ],
   "id": "bfedf42ee2d2e187",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Agent Initialization\n",
    "First, we initialize the agents with a randomized position and orientation, both uniformly distributed."
   ],
   "id": "946c3a8ad7c1020b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:37:34.147513Z",
     "start_time": "2025-02-06T22:37:33.944388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_agents(\n",
    "    num_agents: int = 12, \n",
    "    room_size: tuple = (8., 10.),\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate random positions and orientations for agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100.0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        A tuple containing the positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate random positions within the boundary size centered at 0\n",
    "    x = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[0]\n",
    "    y = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[1]\n",
    "    positions = np.vstack((x, y)).T\n",
    "    \n",
    "    # Generate random orientations (angles in radians between 0 and 2*pi)\n",
    "    rotations = np.random.random(size=(num_agents, )).astype(np.float32) * np.pi * 2\n",
    "    \n",
    "    return positions.astype(np.float32), rotations.astype(np.float32)"
   ],
   "id": "4f404bcb3061544",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Beacon initialization\n",
    "\n",
    "To intrinsically motivate the agents, we need a set of virtual beacons that are populated within the environment. The beacons have a freer representation with only positions needed."
   ],
   "id": "c8523e5fa3d56cdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:37:36.197814Z",
     "start_time": "2025-02-06T22:37:35.992344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def initialize_beacons(\n",
    "        num_beacons = 10,\n",
    "        room_sensing_range = 50.\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Initialize beacons following a uniform distribution scaled to the room's sensing boundary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_beacons : int, default: 10\n",
    "        Number of beacons to initialize.\n",
    "    room_sensing_range : float, default: 50.0\n",
    "        Size of the environment for the generation of beacons.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    beacons      : np.ndarray of shape (num_beacons, 2)\n",
    "        Initial positions of the beacons. \n",
    "    \"\"\"\n",
    "    \n",
    "    beacons = (np.random.random(size=(num_beacons, 2)) - 0.5) * room_sensing_range\n",
    "    return beacons.astype(np.float32)"
   ],
   "id": "38b3585336753b1e",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## External Influence: drift-diffusion vector\n",
    "\n",
    "We want to compute the influence of agent movement direction within a single time step. For this, we specify our internal influence as a 2D drift diffusion model, where the agents are approach a spatial beacon within the room's boundary by reorienting its locomotive direction.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a|j, t} = \\theta_{a|j, t-1} + \\omega_a \\mathrm{d}t + \\mathrm{d}\\phi_t,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{d}\\mathbf{x}_{a|j, t} \n",
    "    &= v_{a|j}\\mathrm{d}t \\frac{\\mathbf{x}_{a|j}}{||\\mathbf{x}_{a|j}||} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t \\\\\n",
    "    &= v_{a}\\mathrm{d}t     \n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|j, t} \\\\\n",
    "        \\sin \\theta_{a|j, t}\n",
    "    \\end{bmatrix} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t,% \\sqrt{\\mathrm{d}t} Z_t.\n",
    "\\end{align}"
   ],
   "id": "abd398a2985b3af7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:37:39.271223Z",
     "start_time": "2025-02-06T22:37:39.004453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def external_influence( \n",
    "    agent_position,\n",
    "    target_position,\n",
    "    noise = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a drift-diffusion vector in 2D space for a single agent \n",
    "    based on a target location (in this case, the position of a beacon).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_position : np.ndarray\n",
    "        The position of the agent.\n",
    "    target_position : np.ndarray\n",
    "        The position of the target beacon.\n",
    "    noise : float, optional\n",
    "        The rate of diffusion, which determines the variability of the direction (default is 0.1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D vector representing the drift-diffusion process towards the target (beacon).\n",
    "    \"\"\"\n",
    "    # Calculate the angle towards the beacon (in radian)\n",
    "    target_angle = np.arctan2(\n",
    "        target_position[1] - agent_position[1], \n",
    "        target_position[0] - agent_position[0]\n",
    "    )\n",
    "    \n",
    "    # Generate a random direction with drift around the target angle\n",
    "    direction = np.random.vonmises(mu=target_angle, kappa=noise)\n",
    "    \n",
    "    # Convert the angle to a unit vector in 2D space\n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32)\n",
    "    \n",
    "    return v"
   ],
   "id": "baee136816ec7fd5",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Internal Influence: particle dynamics\n",
    "\n",
    "Its influence by a collective group of agents is modeled as a self-propelling particle system, as expressed in the Vicsek model:\n",
    "\n",
    "\\begin{align}\n",
    "    \\theta_{a|i, t} &= \\langle \\theta_{i, t}\\rangle_{|\\mathbf{x}_a - \\mathbf{x}_i| < r_a, i \\in I} + \\eta_{a,t-1}, \\\\\n",
    "    \\mathrm{d} \\mathbf{x}_{a|i,t} &= v_{a,t} \\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|i, t} \\\\\n",
    "        \\sin \\theta_{a|i, t}\n",
    "    \\end{bmatrix},\n",
    "\\end{align}"
   ],
   "id": "d993e6f6dfdb3038"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:37:40.974848Z",
     "start_time": "2025-02-06T22:37:40.743978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit \n",
    "def internal_influence(\n",
    "        self_position,\n",
    "        other_positions,\n",
    "        other_rotations,\n",
    "        sensing_radius = 1.5,\n",
    "        noise = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate an influence vector for a single agent \n",
    "    based on the angular component of the Vicsek model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the position of the agent\n",
    "    neighbor_positions : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the positions of the neighboring agents.\n",
    "    neighbor_rotations : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the rotations of the neighboring agents.\n",
    "    sensing_radius : float\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    noise : float, optional\n",
    "        The level of noise to add to the average direction (default is 0.1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D unit vector representing the averaged influence direction with added noise.\n",
    "    \"\"\"\n",
    "      \n",
    "    neighbor_rotations = []\n",
    "    \n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "        \n",
    "        if d <= sensing_radius and d > 0:\n",
    "            neighbor_rotations.append(other_rotations[i])\n",
    "            \n",
    "    if len(neighbor_rotations) == 0:\n",
    "        return np.array([0.0, 0.0], dtype=np.float32)\n",
    "    \n",
    "    neighbor_rotations = np.array(neighbor_rotations)\n",
    "    averaged_rotation = np.sum(neighbor_rotations) / len(neighbor_rotations)\n",
    "    \n",
    "    noise_rotation = (np.random.random() - 0.5) * 2 * noise\n",
    "    direction = averaged_rotation + noise_rotation\n",
    "    \n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32) \n",
    "    \n",
    "    return v"
   ],
   "id": "5e92d44292218f7f",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting everything together: combined influences\n",
    "\n",
    "The combined influences allow us to update the agents' positions and rotations together."
   ],
   "id": "13c0b15cd53302c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:38:08.879694Z",
     "start_time": "2025-02-06T22:38:08.660255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def combined_influences(\n",
    "    agent_positions: np.ndarray = None, \n",
    "    agent_rotations: np.ndarray = None,\n",
    "    beacon_positions: np.ndarray = None,\n",
    "    velocity: float = 1.0, \n",
    "    sensing_radius: float = 2.5,\n",
    "    dt: float = 0.1, \n",
    "    influence_weight: float | np.ndarray = 0.5,\n",
    "    external_noise: float = 0.1,\n",
    "    internal_noise: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the positions and orientations of a single agent \n",
    "    based on velocity and influence vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_positions : np.ndarray\n",
    "        Current positions of the agents.\n",
    "    agent_rotations : np.ndarray\n",
    "        Current orientations of the agents.\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    dt : float, optional\n",
    "        The time step for updating positions and orientations (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight of influence_vector1 in determining new orientations (default is 0.7).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        Updated positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (len(agent_positions) == len(agent_rotations))\n",
    "    \n",
    "    num_agents = agent_positions.shape[0]\n",
    "    num_beacons = beacon_positions.shape[0]\n",
    "    \n",
    "    # Check if the shape of the weight is a float\n",
    "    if isinstance(influence_weight, float):\n",
    "        weights = np.array([influence_weight])\n",
    "        weights = np.broadcast_to(weights, shape=(num_agents, 1))\n",
    "    else:\n",
    "        weights = influence_weight\n",
    "    \n",
    "    # Create new numpy arrays for the updated agent positions and rotations\n",
    "    new_agent_positions = np.zeros((num_agents, 2))\n",
    "    new_agent_rotations = np.zeros((num_agents, ))\n",
    "    num_neighbors = np.zeros((num_agents, ))\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        # Generate the ddm vector for the agent based on its closest beacon\n",
    "        num_neighbors[i] = count_neighbors(agent_positions[i], agent_positions)\n",
    "\n",
    "        distance_to_beacon = []\n",
    "\n",
    "        for b in range(num_beacons):\n",
    "            bx = beacon_positions[b, 0] - agent_positions[i, 0]\n",
    "            by = beacon_positions[b, 1] - agent_positions[i, 1]\n",
    "            distance_to_beacon.append((bx * bx + by * by) ** 0.5)\n",
    "\n",
    "        beacon_id = np.argmin(np.array(distance_to_beacon))\n",
    "\n",
    "        ddm_vector = external_influence(\n",
    "            agent_positions[i], \n",
    "            beacon_positions[beacon_id],\n",
    "            noise=external_noise\n",
    "        )\n",
    "\n",
    "        # Generate the vicsek vector for the agent based on its neighbors (all agents)\n",
    "        vicsek_vector = internal_influence(\n",
    "            self_position=agent_positions[i],\n",
    "            other_positions=agent_positions,\n",
    "            other_rotations=agent_rotations,\n",
    "            sensing_radius=sensing_radius,\n",
    "            noise=internal_noise\n",
    "        )\n",
    "\n",
    "        # Update orientations based on two influence vectors\n",
    "        ddm_influence = np.arctan2(ddm_vector[1], ddm_vector[0])\n",
    "        vicsek_influence = np.arctan2(vicsek_vector[1], vicsek_vector[0])\n",
    "\n",
    "        # Combine influences to update orientations with different weights\n",
    "        new_agent_rotations[i] = agent_rotations[i] + (weights[i].item() * ddm_influence + (1 - weights[i].item()) * vicsek_influence) * dt\n",
    "\n",
    "        # Ensure orientations are within the range [0, 2*pi]\n",
    "        new_agent_rotations[i] = np.mod(new_agent_rotations[i], 2 * np.pi)\n",
    "\n",
    "        # Update positions based on current orientations\n",
    "        new_agent_positions[i, 0] = agent_positions[i, 0] + velocity * np.cos(new_agent_rotations[i].item()) * dt\n",
    "        new_agent_positions[i, 1] = agent_positions[i, 1] + velocity * np.sin(new_agent_rotations[i].item()) * dt\n",
    "\n",
    "    return new_agent_positions, new_agent_rotations, num_neighbors"
   ],
   "id": "ed773df5234411fa",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:38:10.377419Z",
     "start_time": "2025-02-06T22:38:09.399561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_positions, agent_rotations = initialize_agents(12, room_size=room_size)\n",
    "beacon_positions = initialize_beacons(num_beacons=2)\n",
    "new_agent_positions, new_agent_rotations, num_neighbors = combined_influences(agent_positions, agent_rotations, beacon_positions)"
   ],
   "id": "8fab2bd5934c0eec",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation Loop\n",
    "The update allows us to continuously simulate the agents' positions and rotations at a given interval"
   ],
   "id": "9fea369e1e7d1750"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:35:55.297026Z",
     "start_time": "2025-02-06T22:35:55.093610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@njit\n",
    "def simulator_fun(\n",
    "    theta = None,\n",
    "    num_agents: int = 12, \n",
    "    num_beacons: int = 1,\n",
    "    room_size: tuple = (8, 10),\n",
    "    velocity: float = 1.0, \n",
    "    dt: float = 0.001, \n",
    "    influence_weight: float | np.ndarray = 0.7, \n",
    "    sensing_radius: float = 10.0,\n",
    "    external_noise: float = 0.1,\n",
    "    internal_noise: float = 0.1,\n",
    "    time_horizon: float = 30.\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the simulation and store the time series of positions and orientations of agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    num_beacons : int, optional\n",
    "        Number of beacons to generate (default is 1).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100).\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    dt : float, optional\n",
    "        The time step for the update (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight for influence_vector1 in determining new orientations (default is 0.7).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius for the Vicsek model (default is 10.0).\n",
    "    num_timesteps : int, optional\n",
    "        The number of steps to simulate (default is 100).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        The time series of positions and orientations of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if theta is not None: # Unpack tuples of local and shared priors\n",
    "        local_params = theta[0]\n",
    "        shared_params = theta[1]\n",
    "        \n",
    "        weights = local_params.copy()\n",
    "        sensing_radius = shared_params[0].item()\n",
    "        velocity = shared_params[1].item()\n",
    "    else:\n",
    "        weights = np.array([influence_weight], dtype=np.float32)\n",
    "        weights = np.broadcast_to(weights, shape=(num_agents, 1))\n",
    "    \n",
    "    num_timesteps = int(time_horizon / dt)\n",
    "    \n",
    "    \n",
    "    # Initialize positions and orientations\n",
    "    initial_positions, initial_rotations = initialize_agents(num_agents, room_size=room_size)\n",
    "\n",
    "    # Initialize arrays to store time series of positions and orientations\n",
    "    positions = np.zeros((num_timesteps, num_agents, 2))\n",
    "    rotations = np.zeros((num_timesteps, num_agents, ))\n",
    "    neighbors = np.zeros((num_timesteps, num_agents, ))\n",
    "    positions[0] = initial_positions\n",
    "    rotations[0] = initial_rotations\n",
    "    \n",
    "    # Initialize beacons\n",
    "    beacon_positions = initialize_beacons(num_beacons)\n",
    "\n",
    "    # Simulation loop\n",
    "    for t in range(1, num_timesteps):\n",
    "        ps, rs, num_neighbors = combined_influences(\n",
    "            agent_positions=positions[t-1], \n",
    "            agent_rotations=rotations[t-1], \n",
    "            beacon_positions=beacon_positions, \n",
    "            velocity=velocity, \n",
    "            sensing_radius=sensing_radius, \n",
    "            dt=dt, \n",
    "            influence_weight=weights,\n",
    "            external_noise=external_noise,\n",
    "            internal_noise=internal_noise\n",
    "        )\n",
    "\n",
    "        # Store positions and orientations for each time step\n",
    "        positions[t] = ps\n",
    "        rotations[t] = rs\n",
    "        neighbors[t] = num_neighbors\n",
    "\n",
    "    neighbors[0] = neighbors[1]\n",
    "    \n",
    "    rotations = rotations[:,:,np.newaxis]\n",
    "    neighbors = neighbors[:,:,np.newaxis]\n",
    "\n",
    "    return np.concatenate((positions, rotations, neighbors), axis=-1)"
   ],
   "id": "24bd296bb797e8e0",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:19.553797Z",
     "start_time": "2025-02-06T22:41:17.577845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_hypers = partial_pooling_hyper_prior()\n",
    "test_locals = partial_pooling_local_prior(test_hypers)\n",
    "test_shared = partial_pooling_shared_prior()\n",
    "\n",
    "test_thetas = (test_locals, test_shared)\n",
    "test_sim = simulator_fun(test_thetas)"
   ],
   "id": "3f571730bf556b20",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Partial Pooling Generative Model",
   "id": "28e47cb9af6f2f9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:22.228700Z",
     "start_time": "2025-02-06T22:41:22.027273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simulator = Simulator(simulator_fun=partial(simulator_fun, time_horizon=90, dt=1e-2))\n",
    "simulator"
   ],
   "id": "708755ac2eee7023",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bayesflow.simulation.Simulator at 0x24ac380ff10>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:23.775628Z",
     "start_time": "2025-02-06T22:41:23.284487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TwoLevelGenerativeModel(\n",
    "    prior=prior,\n",
    "    simulator=simulator,\n",
    "    simulator_is_batched=False,\n",
    "    name=\"TogetherFlowPP\"\n",
    ")"
   ],
   "id": "5dbbbaf629ea51ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the TogetherFlowPP model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 12, 1)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 9000, 12, 4)\n",
      "INFO:root:Shape of hyper_prior_draws batch after 2 pilot simulations: (batch_size = 2, 2)\n",
      "INFO:root:Shape of local_prior_draws batch after 2 pilot simulations: (batch_size = 2, 12, 1)\n",
      "INFO:root:Shape of shared_prior_draws batch after 2 pilot simulations: (batch_size = 2, 2, 1)\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional prior non-batchable context provided.\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configurator",
   "id": "5093cdc36301f686"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:41:31.891808Z",
     "start_time": "2025-02-06T22:41:31.697674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configurator(input_dict: dict = None, transpose: bool = True):\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    output_dict[\"hyper_parameters\"] = input_dict[\"hyper_prior_draws\"].astype(np.float32, copy=False)\n",
    "    output_dict[\"local_parameters\"] = input_dict[\"local_prior_draws\"].astype(np.float32, copy=False)\n",
    "    \n",
    "    x = input_dict['sim_data'] / 10. \n",
    "    \n",
    "    if transpose:\n",
    "        x = np.moveaxis(x, 2, 1)[:, :, ::10, :]\n",
    "    \n",
    "    output_dict['summary_conditions'] = x.astype(np.float32, copy=False)\n",
    "    \n",
    "    return output_dict"
   ],
   "id": "57ed31f6830c39a6",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neural Approximator\n",
    "\n",
    "How many parameters are there? We have:\n",
    "\n",
    "- Global parameters: $\\alpha_w$, $\\beta_w$, $r$, and $v$;\n",
    "- Local parameters: $w_a$, one for each agent."
   ],
   "id": "628478544ffec3d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:44:10.445024Z",
     "start_time": "2025-02-06T22:44:09.711360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This one generalizes over different numbers of agents\n",
    "summary_net = bf.summary_networks.HierarchicalNetwork([\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.LSTM(units=256)),\n",
    "    bf.summary_networks.DeepSet(summary_dim=128),\n",
    "])\n",
    "\n",
    "local_inference_net = bf.inference_networks.InvertibleNetwork(\n",
    "    num_params=12,\n",
    "    num_coupling_layers=6,\n",
    "    coupling_design=\"spline\",\n",
    "    coupling_settings={\n",
    "        'units': 128,\n",
    "        'activation': 'swish',\n",
    "        'kernel_regularizer': None,\n",
    "        'dropout_prob': 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "global_inference_net = bf.inference_networks.InvertibleNetwork(\n",
    "    num_params=4, \n",
    "    num_coupling_layers=6,\n",
    "    coupling_design=\"spline\",\n",
    "    coupling_settings={\n",
    "        'units': 128,\n",
    "        'activation': 'swish',\n",
    "        'kernel_regularizer': None,\n",
    "        'dropout_prob': 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "local_amortizer = bf.amortizers.AmortizedPosterior(\n",
    "    inference_net=local_inference_net\n",
    ")\n",
    "\n",
    "global_amortizer = bf.amortizers.AmortizedPosterior(\n",
    "    inference_net=global_inference_net\n",
    ")\n",
    "\n",
    "amortizer = bf.amortizers.TwoLevelAmortizedPosterior(\n",
    "    summary_net=summary_net, \n",
    "    local_amortizer=local_amortizer,\n",
    "    global_amortizer=global_amortizer\n",
    ")"
   ],
   "id": "79e603ae939b5335",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Online Training",
   "id": "327f0dc4d8ecd531"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T22:44:14.595605Z",
     "start_time": "2025-02-06T22:44:12.272654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = bf.trainers.Trainer(\n",
    "    amortizer=amortizer,\n",
    "    generative_model=model,\n",
    "    configurator=configurator,\n",
    "    checkpoint_path=\"checkpoints/partial1\"\n",
    ")"
   ],
   "id": "cd2d7e3ef7c83c1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "Could not carry out computations of generative_model ->configurator -> amortizer -> loss! Error trace:\n Exception encountered when calling layer 'act_norm_191' (type ActNorm).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [4] vs. [2,2] [Op:Mul] name: \n\nCall arguments received by layer 'act_norm_191' (type ActNorm):\n  • target=tf.Tensor(shape=(2, 2), dtype=float32)\n  • inverse=False",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:1315\u001B[0m, in \u001B[0;36mTrainer._check_consistency\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1314\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPerforming a consistency check with provided components...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1315\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mamortizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfigurator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerative_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_n_sim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1316\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\amortizers.py:1086\u001B[0m, in \u001B[0;36mTwoLevelAmortizedPosterior.compute_loss\u001B[1;34m(self, input_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1085\u001B[0m local_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_amortizer\u001B[38;5;241m.\u001B[39mcompute_loss(local_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1086\u001B[0m global_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_amortizer\u001B[38;5;241m.\u001B[39mcompute_loss(global_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1087\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLocal.Loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: local_loss, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGlobal.Loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: global_loss}\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\amortizers.py:208\u001B[0m, in \u001B[0;36mAmortizedPosterior.compute_loss\u001B[1;34m(self, input_dict, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# Get amortizer outputs\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m net_out, sum_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(input_dict, return_summary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    209\u001B[0m z, log_det_J \u001B[38;5;241m=\u001B[39m net_out\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\amortizers.py:180\u001B[0m, in \u001B[0;36mAmortizedPosterior.call\u001B[1;34m(self, input_dict, return_summary, **kwargs)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;66;03m# Compute output of inference net\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m net_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_net(input_dict[DEFAULT_KEYS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]], full_cond, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;66;03m# Return summary outputs or not, depending on parameter\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\inference_networks.py:178\u001B[0m, in \u001B[0;36mInvertibleNetwork.call\u001B[1;34m(self, targets, condition, inverse, **kwargs)\u001B[0m\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minverse(targets, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(targets, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\inference_networks.py:215\u001B[0m, in \u001B[0;36mInvertibleNetwork.forward\u001B[1;34m(self, targets, condition, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoupling_layers:\n\u001B[1;32m--> 215\u001B[0m     z, log_det_J \u001B[38;5;241m=\u001B[39m layer(z, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    216\u001B[0m     log_det_Js\u001B[38;5;241m.\u001B[39mappend(log_det_J)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:612\u001B[0m, in \u001B[0;36mCouplingLayer.call\u001B[1;34m(self, target_or_z, condition, inverse, **kwargs)\u001B[0m\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inverse:\n\u001B[1;32m--> 612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(target_or_z, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minverse(target_or_z, condition, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\coupling_networks.py:637\u001B[0m, in \u001B[0;36mCouplingLayer.forward\u001B[1;34m(self, target, condition, **kwargs)\u001B[0m\n\u001B[0;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact_norm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 637\u001B[0m     target, log_det_J_act \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    638\u001B[0m     log_det_Js \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m log_det_J_act\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\helper_networks.py:369\u001B[0m, in \u001B[0;36mActNorm.call\u001B[1;34m(self, target, inverse)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inverse:\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\helper_networks.py:376\u001B[0m, in \u001B[0;36mActNorm._forward\u001B[1;34m(self, target)\u001B[0m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Performs a forward pass through the layer.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 376\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n\u001B[0;32m    377\u001B[0m ldj \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mreduce_sum(tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mlog(tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mabs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale)), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Exception encountered when calling layer 'act_norm_191' (type ActNorm).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [4] vs. [2,2] [Op:Mul] name: \n\nCall arguments received by layer 'act_norm_191' (type ActNorm):\n  • target=tf.Tensor(shape=(2, 2), dtype=float32)\n  • inverse=False",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConfigurationError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[152], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mbf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamortizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamortizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerative_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfigurator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfigurator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcheckpoints/partial1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:220\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, amortizer, generative_model, configurator, checkpoint_path, max_to_keep, default_lr, skip_checks, memory, **kwargs)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;66;03m# Perform a sanity check with provided components\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_checks:\n\u001B[1;32m--> 220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_consistency\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Native\\Permanent\\TogetherFlow\\env\\lib\\site-packages\\bayesflow\\trainers.py:1318\u001B[0m, in \u001B[0;36mTrainer._check_consistency\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1316\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 1318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ConfigurationError(\n\u001B[0;32m   1319\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not carry out computations of generative_model ->\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1320\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurator -> amortizer -> loss! Error trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1321\u001B[0m     )\n",
      "\u001B[1;31mConfigurationError\u001B[0m: Could not carry out computations of generative_model ->configurator -> amortizer -> loss! Error trace:\n Exception encountered when calling layer 'act_norm_191' (type ActNorm).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [4] vs. [2,2] [Op:Mul] name: \n\nCall arguments received by layer 'act_norm_191' (type ActNorm):\n  • target=tf.Tensor(shape=(2, 2), dtype=float32)\n  • inverse=False"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "history = trainer.train_online(epochs=3, batch_size=32, iterations_per_epoch=500)"
   ],
   "id": "4a3187268a42a566"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8e205ccddb9b6ad8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Diagnostics",
   "id": "7b3f27b007c012f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "validation_sim = model(400)\n",
    "validation_configured = configurator(validation_sim)\n",
    "\n",
    "validation_configured[\"parameters\"]"
   ],
   "id": "412c0d878cc0df88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "post_samples = amortizer.sample(validation_configured, n_samples=1000)\n",
    "prior_samples = validation_configured[\"parameters\"]"
   ],
   "id": "907d01b78fe4463b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.set(rc={'axes.facecolor':'#FFFFFF00', 'figure.facecolor':'#FFFFFF00'})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "g = bf.diagnostics.plot_recovery(\n",
    "    post_samples=post_samples, \n",
    "    prior_samples=prior_samples, \n",
    "    param_names=param_names,\n",
    "    color=\"#4E2A84\"\n",
    ")"
   ],
   "id": "5725e4cbebdadde4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "c = bf.diagnostics.plot_z_score_contraction(post_samples=post_samples, prior_samples=prior_samples, param_names=param_names)",
   "id": "a3878000c0e66a46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "h = bf.diagnostics.plot_sbc_histograms(post_samples=post_samples, prior_samples=prior_samples, param_names=param_names, num_bins=10)",
   "id": "643f7dad757ff5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "e = bf.diagnostics.plot_sbc_ecdf(\n",
    "    post_samples=post_samples, \n",
    "    prior_samples=prior_samples, \n",
    "    param_names=param_names, \n",
    "    difference=True,\n",
    "    rank_ecdf_color=\"#4E2A84\"    \n",
    ")"
   ],
   "id": "be937b60c66bfddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "d = bf.diagnostics.plot_posterior_2d(posterior_draws=post_samples[1], prior_draws=prior_samples, param_names=param_names)",
   "id": "7028838ca96baada"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
