{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3160aa9b7b6423b8",
   "metadata": {},
   "source": [
    "# Togetherflow\n",
    "**Emergent agent motion dynamics in immersive rooms**\n",
    "\n",
    "In this notebook, we implement Togetherflow, a computational cognitive model that characterizes the motion pattern of human agents in immersive rooms."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:30.473827Z",
     "start_time": "2025-08-01T16:28:30.471287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    # set this to \"torch\", \"tensorflow\", or \"jax\"\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"jax\""
   ],
   "id": "4222864045cf19d0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6affc593b86588ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:35.730205Z",
     "start_time": "2025-08-01T16:28:32.215229Z"
    }
   },
   "source": [
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import bayesflow as bf\n",
    "\n",
    "from numba import njit\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:2025-08-01 11:28:35,569:jax._src.xla_bridge:502: Jax plugin configuration error: Exception when calling jax_plugins.xla_cuda12.initialize()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/geraldine/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/jax/_src/xla_bridge.py\", line 500, in discover_pjrt_plugins\n",
      "    plugin_module.initialize()\n",
      "  File \"/home/geraldine/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 328, in initialize\n",
      "    _check_cuda_versions(raise_on_first_error=True)\n",
      "  File \"/home/geraldine/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 285, in _check_cuda_versions\n",
      "    local_device_count = cuda_versions.cuda_device_count()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: jaxlib/cuda/versions_helpers.cc:113: operation cuInit(0) failed: CUDA_ERROR_UNKNOWN\n",
      "WARNING:2025-08-01 11:28:35,578:jax._src.xla_bridge:872: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "INFO:bayesflow:Using backend 'jax'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:37.165683Z",
     "start_time": "2025-08-01T16:28:37.160040Z"
    }
   },
   "cell_type": "code",
   "source": "bf.__version__",
   "id": "8f5566c5b25cfc98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "93cad931185e8374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:37.893013Z",
     "start_time": "2025-08-01T16:28:37.880369Z"
    }
   },
   "source": [
    "from boundary_conditions import bound_agent_position\n",
    "from priors import complete_pooling_prior"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "9658492a077e97a0",
   "metadata": {},
   "source": [
    "## Generative Model Definition\n",
    "\n",
    "The movement of any agent $a = 1, ..., A$ is both related to: 1) its interaction with surrounding neighbors $i = 1, ..., I$, which we call *internal influence*, and 2) their motivation to the surrounding spatial objects $b = 1, ..., B$, which we call *external influence*. These influences are modulated by a stationary weight, $w_a$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a, t} = w_a \\theta_{a|j, t} + (1 - w_a) \\theta_{a|i, t}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259991c7e791999",
   "metadata": {},
   "source": [
    "### Meta-Variables\n",
    "\n",
    "First, we define some meta-variables, such as the number of agents to simulate, the number of spatial beacons present in the environment, etc."
   ]
  },
  {
   "cell_type": "code",
   "id": "b9c6adac11e148d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:44.649551Z",
     "start_time": "2025-08-01T16:28:44.646064Z"
    }
   },
   "source": [
    "num_agents = 12\n",
    "num_beacons = 2\n",
    "room_size = (8., 10.)\n",
    "world_size = 25."
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "efa1ed5c2b67daf7",
   "metadata": {},
   "source": [
    "### Agent Initialization\n",
    "\n",
    "First, we initialize the agents with a randomized position and orientation, both uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "id": "51952cb988f59d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:45.555488Z",
     "start_time": "2025-08-01T16:28:45.551558Z"
    }
   },
   "source": [
    "@njit\n",
    "def initialize_agents(\n",
    "    num_agents: int = 12, \n",
    "    room_size: tuple = (8., 10.),\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate random positions and orientations for agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100.0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        A tuple containing the positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate random positions within the boundary size centered at 0\n",
    "    x = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[0]\n",
    "    y = (np.random.random(size=num_agents).astype(np.float32) - 0.5) * room_size[1]\n",
    "    positions = np.vstack((x, y)).T\n",
    "    \n",
    "    # Generate random orientations (angles in radians between 0 and 2*pi)\n",
    "    rotations = np.random.random(size=(num_agents, )).astype(np.float32) * np.pi * 2\n",
    "    \n",
    "    return positions.astype(np.float32), rotations.astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "821eaed55db551a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:46.685567Z",
     "start_time": "2025-08-01T16:28:45.964406Z"
    }
   },
   "source": [
    "agent_positions, agent_rotations = initialize_agents(room_size=room_size, num_agents=12)\n",
    "agent_positions[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4014795,  3.1287212], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "d32f0945c82f1da0",
   "metadata": {},
   "source": [
    "### Beacon initialization\n",
    "\n",
    "To intrinsically motivate the agents, we need a set of virtual beacons that are populated within the environment. The beacons have a freer representation with only positions needed."
   ]
  },
  {
   "cell_type": "code",
   "id": "82551c4e3ba9a4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:46.876442Z",
     "start_time": "2025-08-01T16:28:46.873939Z"
    }
   },
   "source": [
    "@njit\n",
    "def initialize_beacons(\n",
    "        num_beacons = 10,\n",
    "        room_sensing_range = 50.\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Initialize beacons following a uniform distribution scaled to the room's sensing boundary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_beacons : int, default: 10\n",
    "        Number of beacons to initialize.\n",
    "    room_sensing_range : float, default: 50.0\n",
    "        Sensing distance of the room for the beacons to matter.\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    beacons      : np.ndarray of shape (num_beacons, 2)\n",
    "        Initial positions of the beacons. \n",
    "    \"\"\"\n",
    "    \n",
    "    beacons = (np.random.random(size=(num_beacons, 2)) - 0.5) * room_sensing_range\n",
    "    return beacons.astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "7ea13da39adf26f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:47.596140Z",
     "start_time": "2025-08-01T16:28:47.467987Z"
    }
   },
   "source": [
    "beacon_positions = initialize_beacons(num_beacons=1, room_sensing_range=world_size)\n",
    "beacon_positions"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06069824, -5.053933  ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e9542ab4709c2797",
   "metadata": {},
   "source": [
    "## External Influence: drift-diffusion vector\n",
    "\n",
    "We want to compute the influence of agent movement direction within a single time step. For this, we specify our internal influence as a 2D drift diffusion model, where the agents are approach a spatial beacon within the room's boundary by reorienting its locomotive direction.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta_{a|j, t} = \\theta_{a|j, t-1} + \\omega_a \\mathrm{d}t + \\mathrm{d}\\phi_t,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{d}\\mathbf{x}_{a|j, t} \n",
    "    &= v_{a|j}\\mathrm{d}t \\frac{\\mathbf{x}_{a|j}}{||\\mathbf{x}_{a|j}||} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t \\\\\n",
    "    &= v_{a}\\mathrm{d}t     \n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|j, t} \\\\\n",
    "        \\sin \\theta_{a|j, t}\n",
    "    \\end{bmatrix} + \\sigma_{a|j} \\mathrm{d}\\mathrm{W}_t,% \\sqrt{\\mathrm{d}t} Z_t.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e2b631340d95c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:48.599592Z",
     "start_time": "2025-08-01T16:28:48.594813Z"
    }
   },
   "source": [
    "@njit\n",
    "def external_influence( \n",
    "    agent_position,\n",
    "    beacon_position,\n",
    "    noise = False,\n",
    "    noise_amplitude = 0.01\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a drift-diffusion vector in 2D space for a single agent \n",
    "    based on a target location (in this case, the position of a beacon).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_position : np.ndarray\n",
    "        The position of the agent.\n",
    "    target_position : np.ndarray\n",
    "        The position of the target beacon.\n",
    "    focus : float, optional\n",
    "        The dispersion of a von Mises distribution for rotational noise influenced by the neighbors.\n",
    "        The higher the value is, the less perturbation there would be.\n",
    "    noise: bool, optional\n",
    "        Whether the focus is interpreted as noise amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D vector representing the drift-diffusion process towards the target (beacon).\n",
    "    \"\"\"\n",
    "    # Calculate the angle towards the beacon (in radian)\n",
    "    beacon_direction = np.arctan2(\n",
    "        beacon_position[1] - agent_position[1], \n",
    "        beacon_position[0] - agent_position[0]\n",
    "    )\n",
    "    \n",
    "    # Generate a random direction with drift around the target angle\n",
    "    if noise:\n",
    "        beacon_direction = beacon_direction + (np.random.random() - 0.5) * noise_amplitude\n",
    "        # beacon_direction = beacon_direction + np.random.vonmises(0., 8.) * noise_amplitude\n",
    "    \n",
    "    # Convert the angle to a unit vector in 2D space\n",
    "    v = np.array([np.cos(beacon_direction), np.sin(beacon_direction)], dtype=np.float32)\n",
    "    \n",
    "    return v"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "b7ed437861fa154d",
   "metadata": {},
   "source": [
    "## Internal Influence: particle dynamics\n",
    "\n",
    "Its influence by a collective group of agents is modeled as a self-propelling particle system, as expressed in the Vicsek model:\n",
    "\n",
    "\\begin{align}\n",
    "    \\theta_{a|i, t} &= \\langle \\theta_{i, t}\\rangle_{|\\mathbf{x}_a - \\mathbf{x}_i| < r_a, i \\in I} + \\eta_{a,t-1}, \\\\\n",
    "    \\mathrm{d} \\mathbf{x}_{a|i,t} &= v_{a,t} \\mathrm{d}t\n",
    "    \\begin{bmatrix}\n",
    "        \\cos \\theta_{a|i, t} \\\\\n",
    "        \\sin \\theta_{a|i, t}\n",
    "    \\end{bmatrix},\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c1c130171b5e025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:49.509439Z",
     "start_time": "2025-08-01T16:28:49.503343Z"
    }
   },
   "source": [
    "@njit \n",
    "def internal_influence(\n",
    "        self_position,\n",
    "        other_positions,\n",
    "        other_rotations,\n",
    "        sensing_radius = 1.5,\n",
    "        focus = 0.01,\n",
    "        noise = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate an influence vector for a single agent \n",
    "    based on the angular component of the Vicsek model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the position of the agent\n",
    "    other_positions : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the positions of the neighboring agents.\n",
    "    other_rotations : np.ndarray of shape (2,)\n",
    "        A 2D vector representing the rotations of the neighboring agents.\n",
    "    sensing_radius : float\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    focus : float, optional\n",
    "        The dispersion of a von Mises distribution for rotational noise influenced by the neighbors.\n",
    "        The higher the value is, the less perturbation there would be.\n",
    "    noise: bool, optional\n",
    "        Whether the focus is interpreted as noise amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D unit vector representing the averaged influence direction with added noise.\n",
    "    \"\"\"\n",
    "      \n",
    "    neighbor_rotations = []\n",
    "    \n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "        \n",
    "        if d <= sensing_radius and d > 0:\n",
    "            neighbor_rotations.append(other_rotations[i])\n",
    "        \n",
    "    if len(neighbor_rotations) == 0:\n",
    "        return np.array([0.0, 0.0], dtype=np.float32)\n",
    "    \n",
    "    neighbor_rotations = np.array(neighbor_rotations)\n",
    "    averaged_rotation = np.sum(neighbor_rotations) / len(neighbor_rotations)\n",
    "    \n",
    "    if noise:\n",
    "        deviation = (np.random.random() - 0.5) * focus\n",
    "    else:\n",
    "        deviation = np.random.vonmises(mu=0., kappa=4.) * focus\n",
    "    direction = averaged_rotation + deviation\n",
    "    \n",
    "    v = np.array([np.cos(direction), np.sin(direction)], dtype=np.float32) \n",
    "    \n",
    "    return v"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "91373437a7e2011d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:49.989641Z",
     "start_time": "2025-08-01T16:28:49.986677Z"
    }
   },
   "source": [
    "deviation = np.random.vonmises(mu=0., kappa=4.) * 1\n",
    "deviation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12293777182850452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "89b26efb60883d8c",
   "metadata": {},
   "source": [
    "## Putting everything together: combined influences\n",
    "\n",
    "The combined influences allow us to update the agents' positions and rotations together."
   ]
  },
  {
   "cell_type": "code",
   "id": "e6d209229bb844b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:50.816305Z",
     "start_time": "2025-08-01T16:28:50.810533Z"
    }
   },
   "source": [
    "@njit\n",
    "def count_neighbors(self_position, other_positions, sensing_radius = 1.5):\n",
    "    \"\"\"\n",
    "    Helper function that counts the number of neighbors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    self_position   : np.ndarray of size (2)\n",
    "        The position of the agent itself\n",
    "    other_positions : np.ndarray of size (num_agents, 2)\n",
    "        The positions of all agents\n",
    "    sensing_radius  : float, default: 1.5\n",
    "        The sensing radius of the agent\n",
    "        \n",
    "    Returns \n",
    "    -------\n",
    "    num_neighbors   : int, default: 0\n",
    "        The number of neighbors within the agent's sensing radius.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_neighbors = 0\n",
    "    \n",
    "    for i in range(len(other_positions)):\n",
    "        dx = other_positions[i, 0] - self_position[0]\n",
    "        dy = other_positions[i, 1] - self_position[1]\n",
    "        d = (dx ** 2 + dy ** 2) ** 0.5\n",
    "        \n",
    "        if d <= sensing_radius and d > 0:\n",
    "            num_neighbors += 1\n",
    "\n",
    "    return num_neighbors"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "677d2029649e31d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:51.331612Z",
     "start_time": "2025-08-01T16:28:51.230110Z"
    }
   },
   "source": [
    "num_neighbors = count_neighbors(agent_positions[8], agent_positions)\n",
    "num_neighbors"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "774c703377880763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:51.700166Z",
     "start_time": "2025-08-01T16:28:51.694819Z"
    }
   },
   "source": [
    "@njit\n",
    "def combined_influences(\n",
    "    agent_positions: np.ndarray = None, \n",
    "    agent_rotations: np.ndarray = None,\n",
    "    beacon_positions: np.ndarray = None,\n",
    "    velocity: float = 1.0, \n",
    "    sensing_radius: float = 2.5,\n",
    "    dt: float = 0.1, \n",
    "    influence_weight: float = 0.5,\n",
    "    internal_focus: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the positions and orientations of a single agent \n",
    "    based on velocity and influence vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agent_positions : np.ndarray\n",
    "        Current positions of the agents.\n",
    "    agent_rotations : np.ndarray\n",
    "        Current orientations of the agents.\n",
    "    beacon_positions : np.ndarray\n",
    "        Positions of the beacons.\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius within which agents interact with their neighbors.\n",
    "    dt : float, optional\n",
    "        The time step for updating positions and orientations (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight of influence_vector1 in determining new orientations (default is 0.7).\n",
    "    external_focus : float, optional\n",
    "        Concentration of the agent's rotational noise influenced by the beacons\n",
    "    internal_focus : float, optional\n",
    "        Concentration of the agent's rotational noise influenced by the neighbors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        Updated positions (np.ndarray) and orientations (np.ndarray) of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (len(agent_positions) == len(agent_rotations))\n",
    "    \n",
    "    num_agents = agent_positions.shape[0]\n",
    "    num_beacons = beacon_positions.shape[0]\n",
    "    \n",
    "    # Create new numpy arrays for the updated agent positions and rotations\n",
    "    new_agent_positions = np.zeros((num_agents, 2))\n",
    "    new_agent_rotations = np.zeros((num_agents, ))\n",
    "    num_neighbors = np.zeros((num_agents, ))\n",
    "    \n",
    "    \n",
    "    for i in range(num_agents):\n",
    "        \n",
    "        num_neighbors[i] = count_neighbors(agent_positions[i], agent_positions)\n",
    "        \n",
    "        # Generate the ddm vector for the agent based on its closest beacon\n",
    "        distance_to_beacon = []\n",
    "        \n",
    "        for b in range(num_beacons):\n",
    "            bx = beacon_positions[b, 0] - agent_positions[i, 0]\n",
    "            by = beacon_positions[b, 1] - agent_positions[i, 1]\n",
    "            distance_to_beacon.append((bx * bx + by * by) ** 0.5)\n",
    "        \n",
    "        beacon_id = np.argmin(np.array(distance_to_beacon))\n",
    "        \n",
    "        ddm_vector = external_influence(\n",
    "            agent_positions[i], \n",
    "            beacon_positions[beacon_id],\n",
    "            #focus=external_focus\n",
    "        )\n",
    "        \n",
    "        # Generate the vicsek vector for the agent based on its neighbors (all agents)\n",
    "        vicsek_vector = internal_influence(\n",
    "            self_position=agent_positions[i],\n",
    "            other_positions=agent_positions,\n",
    "            other_rotations=agent_rotations,\n",
    "            sensing_radius=sensing_radius,\n",
    "            focus=internal_focus\n",
    "        )\n",
    "\n",
    "        # Update orientations based on two influence vectors\n",
    "        ddm_influence = np.arctan2(ddm_vector[1], ddm_vector[0])\n",
    "        vicsek_influence = np.arctan2(vicsek_vector[1], vicsek_vector[0])\n",
    "        \n",
    "        # Combine influences to update orientations with different weights\n",
    "        new_agent_rotations[i] = agent_rotations[i] + (influence_weight * ddm_influence + (1 - influence_weight) * vicsek_influence) * dt\n",
    "        \n",
    "        # Ensure orientations are within the range [0, 2*pi]\n",
    "        new_agent_rotations[i] = np.mod(new_agent_rotations[i], 2 * np.pi)\n",
    "        \n",
    "        # Update positions based on current orientations\n",
    "        new_agent_positions[i, 0] = agent_positions[i, 0] + velocity * np.cos(new_agent_rotations[i].item()) * dt\n",
    "        new_agent_positions[i, 1] = agent_positions[i, 1] + velocity * np.sin(new_agent_rotations[i].item()) * dt\n",
    "        \n",
    "        new_agent_positions[i] = bound_agent_position(new_agent_positions[i], room_size=room_size)\n",
    "    \n",
    "    return new_agent_positions, new_agent_rotations, num_neighbors"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "a49a2a18043032c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:54.214259Z",
     "start_time": "2025-08-01T16:28:52.165118Z"
    }
   },
   "source": [
    "agent_positions, agent_rotations = initialize_agents(12, room_size=room_size)\n",
    "beacon_positions = initialize_beacons(num_beacons=2)\n",
    "new_agent_positions, new_agent_rotations, num_neighbors = combined_influences(agent_positions, agent_rotations, beacon_positions)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "4cc450e89dc648e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:54.231286Z",
     "start_time": "2025-08-01T16:28:54.228703Z"
    }
   },
   "source": [
    "np.concatenate([agent_positions, new_agent_positions], axis=1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.24748945, -3.79886842, -2.32927979, -3.85640397],\n",
       "       [ 2.48891354, -0.20938396,  2.55447376, -0.13387332],\n",
       "       [-3.90100646, -0.65359741, -3.99564472, -0.6859022 ],\n",
       "       [-3.60041904,  1.31699204, -3.54246632,  1.23549676],\n",
       "       [-1.94633961,  1.90987349, -2.02856119,  1.96679107],\n",
       "       [ 3.95093441, -0.67142785,  3.85117926, -0.66443432],\n",
       "       [-2.99569178,  1.72765374, -3.06166277,  1.65250171],\n",
       "       [ 2.20391703, -0.5472967 ,  2.10391992, -0.54653591],\n",
       "       [-2.65880108, -2.53848815, -2.68715047, -2.63438555],\n",
       "       [-2.48826838,  1.70719147, -2.39834205,  1.66345068],\n",
       "       [-3.94412088,  0.94708145, -3.92165187,  1.04452447],\n",
       "       [ 3.6583972 ,  4.72213793,  3.59215189,  4.79704827]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "929f633c3e4c531d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:54.307722Z",
     "start_time": "2025-08-01T16:28:54.305220Z"
    }
   },
   "source": [
    "np.vstack([agent_rotations, new_agent_rotations]).T"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.87209439, 3.75463144],\n",
       "       [0.71661103, 0.85581647],\n",
       "       [3.65057278, 3.4705409 ],\n",
       "       [5.50069571, 5.33053743],\n",
       "       [2.64803958, 2.53608949],\n",
       "       [2.9866221 , 3.07160029],\n",
       "       [4.14444828, 3.99195622],\n",
       "       [3.05231404, 3.13398464],\n",
       "       [4.61089373, 4.42495346],\n",
       "       [5.98538351, 5.8304712 ],\n",
       "       [1.49852467, 1.34417134],\n",
       "       [2.32194328, 2.2948851 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "e454203744dc87b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:54.496441Z",
     "start_time": "2025-08-01T16:28:54.494019Z"
    }
   },
   "source": [
    "num_neighbors"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 3., 2., 0., 4., 1., 1., 3., 2., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "c1574a5dfdf2a7a6",
   "metadata": {},
   "source": [
    "## Simulation Loop\n",
    "\n",
    "The update allows us to continuously simulate the agents' positions and rotations at a given interval"
   ]
  },
  {
   "cell_type": "code",
   "id": "d053d64adc048467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:54.691116Z",
     "start_time": "2025-08-01T16:28:54.683566Z"
    }
   },
   "source": [
    "@njit\n",
    "def simulator_fun(\n",
    "    theta = None,\n",
    "    num_agents: int = 12, \n",
    "    num_beacons: int = 1,\n",
    "    room_size: tuple = (8, 10),\n",
    "    velocity: float = 1.0, \n",
    "    dt: float = 0.001, \n",
    "    influence_weight: float = 0.7, \n",
    "    sensing_radius: float = 10.0,\n",
    "    internal_focus: float = 0.1,\n",
    "    time_horizon: float = 30.\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the simulation and store the time series of positions and orientations of agents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : np.ndarray\n",
    "        Prior parameters specifying the internal properties of the agents\n",
    "    num_agents : int, optional\n",
    "        Number of agents to generate (default is 100).\n",
    "    num_beacons : int, optional\n",
    "        Number of beacons to generate (default is 1).\n",
    "    room_size : float, optional\n",
    "        The size of the boundary within which positions are generated (default is 100).\n",
    "    velocity : float, optional\n",
    "        The speed at which agents move (default is 1.0).\n",
    "    dt : float, optional\n",
    "        The time step for the update (default is 0.1).\n",
    "    influence_weight : float, optional\n",
    "        The weight for influence_vector1 in determining new orientations (default is 0.7).\n",
    "    sensing_radius : float, optional\n",
    "        The sensing radius for the Vicsek model (default is 10.0).\n",
    "    num_timesteps : int, optional\n",
    "        The number of steps to simulate (default is 100).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of np.ndarray\n",
    "        The time series of positions and orientations of the agents.\n",
    "    \"\"\"\n",
    "    \n",
    "    if theta is not None:\n",
    "        influence_weight = theta[0]\n",
    "        sensing_radius = theta[1]\n",
    "        velocity = theta[2]\n",
    "        #internal_focus = theta[3]\n",
    "    \n",
    "    \n",
    "    num_timesteps = int(time_horizon / dt)\n",
    "\n",
    "    # Apply radial bound with sigmoid transformation for the sensing radius\n",
    "    # (r_min, r_max) = (1., 5.)\n",
    "    # sensing_radius = r_min + (r_max - r_min) * (1. / (1. + np.exp(-sensing_radius)))\n",
    "    \n",
    "    # Initialize positions and orientations\n",
    "    initial_positions, initial_rotations = initialize_agents(num_agents, room_size=room_size)\n",
    "\n",
    "    # Initialize arrays to store time series of positions and orientations\n",
    "    positions = np.zeros((num_timesteps, num_agents, 2))\n",
    "    rotations = np.zeros((num_timesteps, num_agents, ))\n",
    "    neighbors = np.zeros((num_timesteps, num_agents, ))\n",
    "    positions[0] = initial_positions\n",
    "    rotations[0] = initial_rotations\n",
    "    \n",
    "    # Initialize beacons\n",
    "    beacon_positions = initialize_beacons(num_beacons)\n",
    "\n",
    "    # Simulation loop\n",
    "    for t in range(1, num_timesteps):\n",
    "        ps, rs, num_neighbors = combined_influences(\n",
    "            agent_positions=positions[t-1], \n",
    "            agent_rotations=rotations[t-1], \n",
    "            beacon_positions=beacon_positions, \n",
    "            velocity=velocity, \n",
    "            sensing_radius=sensing_radius, \n",
    "            dt=dt, \n",
    "            influence_weight=influence_weight,\n",
    "            internal_focus=internal_focus\n",
    "        )\n",
    "        \n",
    "        # Store positions and orientations for each time step\n",
    "        positions[t] = ps\n",
    "        rotations[t] = rs\n",
    "        neighbors[t] = num_neighbors\n",
    "    \n",
    "    neighbors[0] = neighbors[1]    \n",
    "    \n",
    "    rotations = rotations[:,:,np.newaxis]\n",
    "    neighbors = neighbors[:,:,np.newaxis]\n",
    "\n",
    "    return np.concatenate((positions, rotations, neighbors), axis=-1)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "25a3bf0182f2de6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:58.187032Z",
     "start_time": "2025-08-01T16:28:55.481026Z"
    }
   },
   "source": [
    "simulation = simulator_fun(num_agents=49)\n",
    "simulation[:,:,-1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 2., ..., 5., 4., 2.],\n",
       "       [1., 2., 2., ..., 5., 4., 2.],\n",
       "       [1., 2., 2., ..., 5., 4., 2.],\n",
       "       ...,\n",
       "       [1., 0., 2., ..., 5., 2., 2.],\n",
       "       [1., 0., 2., ..., 5., 2., 2.],\n",
       "       [1., 0., 2., ..., 5., 2., 2.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:28:59.705693Z",
     "start_time": "2025-08-01T16:28:59.698402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TogetherFlowSimulator:\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_agents: int = 12,\n",
    "                 num_beacons: int = 1,\n",
    "                 room_size: tuple = (8, 10),\n",
    "                 dt: float = 0.001,\n",
    "                 internal_focus: float = 0.1,\n",
    "                 time_horizon: float = 30.,\n",
    "                 downsample: bool = True,\n",
    "                 downsample_factor: int = 10\n",
    "                 ):\n",
    "        self.num_agents = num_agents\n",
    "        self.num_beacons = num_beacons\n",
    "        self.room_size = room_size\n",
    "        self.dt = dt\n",
    "        self.internal_focus = internal_focus\n",
    "        self.time_horizon = time_horizon\n",
    "        self.downsample = downsample\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.num_timesteps = int(time_horizon / dt)\n",
    "\n",
    "\n",
    "    def sample(self, batch_shape: int | tuple = (1,)) -> dict[str, np.ndarray]:\n",
    "\n",
    "        batch_size = batch_shape[0]\n",
    "        thetas = []\n",
    "        samples = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            theta = complete_pooling_prior()\n",
    "            sim = simulator_fun(\n",
    "                theta=theta,\n",
    "                num_agents=self.num_agents,\n",
    "                num_beacons=self.num_beacons,\n",
    "                room_size=self.room_size,\n",
    "                dt=self.dt,\n",
    "                internal_focus=self.internal_focus,\n",
    "                time_horizon=self.time_horizon\n",
    "            )\n",
    "            thetas.append(theta)\n",
    "            samples.append(sim)\n",
    "\n",
    "        thetas = np.array(thetas)\n",
    "        samples = np.array(samples)\n",
    "\n",
    "        if self.downsample:\n",
    "            samples = samples[:,::self.downsample_factor,:,:]\n",
    "\n",
    "        B, T, A, D = samples.shape\n",
    "\n",
    "        positions = samples[:,:,:,0:2].reshape((B, T, A*2))\n",
    "        rotations = samples[:,:,:,2].reshape((B, T, A))\n",
    "        neighbors = samples[:,:,:,3].reshape((B, T, A))\n",
    "\n",
    "        return dict(\n",
    "            w = thetas[:,0],\n",
    "            r = thetas[:,1],\n",
    "            v = thetas[:,2],\n",
    "            positions = positions,\n",
    "            rotations = rotations,\n",
    "            neighbors = neighbors\n",
    "        )"
   ],
   "id": "47ac4e0082199253",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:08.515818Z",
     "start_time": "2025-08-01T16:29:00.482910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simulator = TogetherFlowSimulator(num_agents=49)\n",
    "test_sims = simulator.sample(batch_shape=(10,))\n",
    "\n",
    "print(test_sims['w'].shape)\n",
    "print(test_sims['r'].shape)\n",
    "print(test_sims['v'].shape)\n",
    "print(test_sims['positions'].shape)\n",
    "print(test_sims['rotations'].shape)\n",
    "print(test_sims['neighbors'].shape)"
   ],
   "id": "7aa62652f75f4c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10, 3000, 98)\n",
      "(10, 3000, 49)\n",
      "(10, 3000, 49)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "4c65e69c3f1780ad",
   "metadata": {},
   "source": "## Adapter"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:10.499068Z",
     "start_time": "2025-08-01T16:29:10.495379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .as_time_series([\"positions\", \"rotations\", \"neighbors\"])\n",
    "    .expand_dims(['w', 'r', 'v'], axis=-1)\n",
    "    .concatenate(['w', 'r', 'v'], into=\"inference_variables\")\n",
    "    .concatenate([\"positions\", \"rotations\", \"neighbors\"], into=\"summary_variables\", axis=-1)\n",
    ")"
   ],
   "id": "5d330b144018cb00",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:20.479804Z",
     "start_time": "2025-08-01T16:29:13.107409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adapted_simulator = TogetherFlowSimulator(num_agents=49)\n",
    "adapter_sim = adapter(adapted_simulator.sample(batch_shape=(10,)))"
   ],
   "id": "e8dd15591bc6e246",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:45.307172Z",
     "start_time": "2025-08-01T16:29:45.304354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(adapter_sim['summary_variables'].shape)\n",
    "print(adapter_sim['inference_variables'].shape)"
   ],
   "id": "170c1eecc3d86150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3000, 196)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "8a465e6568cebf17",
   "metadata": {},
   "source": [
    "# Neural Approximator"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:46.343858Z",
     "start_time": "2025-08-01T16:29:46.325482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This one generalizes over different numbers of agents\n",
    "summary_net = keras.Sequential([\n",
    "    keras.layers.Conv1D(filters=32, kernel_size=2, strides=2, activation=\"elu\"),\n",
    "    keras.layers.Conv1D(filters=32, kernel_size=2, strides=2, activation=\"elu\"),\n",
    "    keras.layers.LSTM(512),\n",
    "    keras.layers.Dense(64)\n",
    "])"
   ],
   "id": "40cfd3c9ec4df8af",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:47.339244Z",
     "start_time": "2025-08-01T16:29:46.973766Z"
    }
   },
   "cell_type": "code",
   "source": "inference_net = bf.networks.DiffusionModel()",
   "id": "78e940ee713f6762",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:29:47.998913Z",
     "start_time": "2025-08-01T16:29:47.995811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = bf.workflows.BasicWorkflow(\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    summary_network=summary_net,\n",
    "    inference_network=inference_net\n",
    ")"
   ],
   "id": "ef68d7671ac653ad",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:32:29.186549Z",
     "start_time": "2025-08-01T16:30:02.959170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_set = workflow.simulate((200,))\n",
    "validation_set = workflow.simulate((10,))"
   ],
   "id": "de7c0ffe98d3f7c7",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:33:03.073869Z",
     "start_time": "2025-08-01T16:32:59.979217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = workflow.fit_offline(\n",
    "    data=training_set,\n",
    "    validation_set=validation_set,\n",
    "    batch_size=32,\n",
    "    epochs=1\n",
    ")"
   ],
   "id": "98b4a67ac1c5d8d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OfflineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.compute_metrics() got an unexpected keyword argument 'stage'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m history = \u001B[43mworkflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_offline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtraining_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m      6\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/workflows/basic_workflow.py:722\u001B[39m, in \u001B[36mBasicWorkflow.fit_offline\u001B[39m\u001B[34m(self, data, epochs, batch_size, keep_optimizer, validation_data, augmentations, **kwargs)\u001B[39m\n\u001B[32m    677\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    678\u001B[39m \u001B[33;03mTrain the approximator offline using a fixed dataset. This approach will be faster than online training,\u001B[39;00m\n\u001B[32m    679\u001B[39m \u001B[33;03msince no computation time is spent in generating new data for each batch, but it assumes that simulations\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    717\u001B[39m \u001B[33;03m    metric evolution over epochs.\u001B[39;00m\n\u001B[32m    718\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    720\u001B[39m dataset = OfflineDataset(data=data, batch_size=batch_size, adapter=\u001B[38;5;28mself\u001B[39m.adapter, augmentations=augmentations)\n\u001B[32m--> \u001B[39m\u001B[32m722\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    723\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    724\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43moffline\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    726\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeep_optimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    727\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    728\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    729\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/workflows/basic_workflow.py:964\u001B[39m, in \u001B[36mBasicWorkflow._fit\u001B[39m\u001B[34m(self, dataset, epochs, strategy, keep_optimizer, validation_data, **kwargs)\u001B[39m\n\u001B[32m    961\u001B[39m     \u001B[38;5;28mself\u001B[39m.approximator.compile(optimizer=\u001B[38;5;28mself\u001B[39m.optimizer, metrics=kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mmetrics\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    963\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m964\u001B[39m     \u001B[38;5;28mself\u001B[39m.history = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapproximator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    965\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    966\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    967\u001B[39m     \u001B[38;5;28mself\u001B[39m._on_training_finished()\n\u001B[32m    968\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.history\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/continuous_approximator.py:315\u001B[39m, in \u001B[36mContinuousApproximator.fit\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    263\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m    264\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    265\u001B[39m \u001B[33;03m    Trains the approximator on the provided dataset or on-demand data generated from the given simulator.\u001B[39;00m\n\u001B[32m    266\u001B[39m \u001B[33;03m    If `dataset` is not provided, a dataset is built from the `simulator`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    313\u001B[39m \u001B[33;03m        If both `dataset` and `simulator` are provided or neither is provided.\u001B[39;00m\n\u001B[32m    314\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapter\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madapter\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/approximator.py:139\u001B[39m, in \u001B[36mApproximator.fit\u001B[39m\u001B[34m(self, dataset, simulator, **kwargs)\u001B[39m\n\u001B[32m    136\u001B[39m     mock_data_shapes = keras.tree.map_structure(keras.ops.shape, mock_data)\n\u001B[32m    137\u001B[39m     \u001B[38;5;28mself\u001B[39m.build(mock_data_shapes)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/backend_approximators/backend_approximator.py:20\u001B[39m, in \u001B[36mBackendApproximator.fit\u001B[39m\u001B[34m(self, dataset, **kwargs)\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, *, dataset: keras.utils.PyDataset, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfilter_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "    \u001B[31m[... skipping hidden 13 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/backend_approximators/jax_approximator.py:208\u001B[39m, in \u001B[36mJAXApproximator.train_step\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtrain_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m    196\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    197\u001B[39m \u001B[33;03m    Alias to `stateless_train_step` for compatibility with `keras.Model`.\u001B[39;00m\n\u001B[32m    198\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    206\u001B[39m \u001B[33;03m    See `stateless_train_step`.\u001B[39;00m\n\u001B[32m    207\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m208\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstateless_train_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/backend_approximators/jax_approximator.py:166\u001B[39m, in \u001B[36mJAXApproximator.stateless_train_step\u001B[39m\u001B[34m(self, state, data)\u001B[39m\n\u001B[32m    162\u001B[39m trainable_variables, non_trainable_variables, optimizer_variables, metrics_variables = state\n\u001B[32m    164\u001B[39m grad_fn = jax.value_and_grad(\u001B[38;5;28mself\u001B[39m.stateless_compute_metrics, has_aux=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m (loss, aux), grads = \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    167\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_trainable_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstage\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtraining\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m    168\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    169\u001B[39m metrics, non_trainable_variables, metrics_variables = aux\n\u001B[32m    171\u001B[39m trainable_variables, optimizer_variables = \u001B[38;5;28mself\u001B[39m.optimizer.stateless_apply(\n\u001B[32m    172\u001B[39m     optimizer_variables, grads, trainable_variables\n\u001B[32m    173\u001B[39m )\n",
      "    \u001B[31m[... skipping hidden 10 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/backend_approximators/jax_approximator.py:104\u001B[39m, in \u001B[36mJAXApproximator.stateless_compute_metrics\u001B[39m\u001B[34m(self, trainable_variables, non_trainable_variables, metrics_variables, data, stage)\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m keras.StatelessScope(state_mapping) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[32m    103\u001B[39m     kwargs = filter_kwargs(data | {\u001B[33m\"\u001B[39m\u001B[33mstage\u001B[39m\u001B[33m\"\u001B[39m: stage}, \u001B[38;5;28mself\u001B[39m.compute_metrics)\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    106\u001B[39m \u001B[38;5;66;03m# update variables\u001B[39;00m\n\u001B[32m    107\u001B[39m non_trainable_variables = [scope.get_current_value(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.non_trainable_variables]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/continuous_approximator.py:216\u001B[39m, in \u001B[36mContinuousApproximator.compute_metrics\u001B[39m\u001B[34m(self, inference_variables, inference_conditions, summary_variables, sample_weight, stage)\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_metrics\u001B[39m(\n\u001B[32m    176\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    177\u001B[39m     inference_variables: Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    181\u001B[39m     stage: \u001B[38;5;28mstr\u001B[39m = \u001B[33m\"\u001B[39m\u001B[33mtraining\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    182\u001B[39m ) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Tensor]:\n\u001B[32m    183\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    184\u001B[39m \u001B[33;03m    Computes loss and tracks metrics for the inference and summary networks.\u001B[39;00m\n\u001B[32m    185\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    213\u001B[39m \u001B[33;03m        \"inference_\" or \"summary_\" to indicate its source.\u001B[39;00m\n\u001B[32m    214\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m     summary_metrics, summary_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_compute_summary_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstage\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33minference_conditions\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.standardize:\n\u001B[32m    219\u001B[39m         inference_conditions = \u001B[38;5;28mself\u001B[39m.standardize_layers[\u001B[33m\"\u001B[39m\u001B[33minference_conditions\u001B[39m\u001B[33m\"\u001B[39m](inference_conditions, stage=stage)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Research/Projects/TogetherFlow/.venv/lib/python3.12/site-packages/bayesflow/approximators/continuous_approximator.py:252\u001B[39m, in \u001B[36mContinuousApproximator._compute_summary_metrics\u001B[39m\u001B[34m(self, summary_variables, stage)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33msummary_variables\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.standardize:\n\u001B[32m    250\u001B[39m     summary_variables = \u001B[38;5;28mself\u001B[39m.standardize_layers[\u001B[33m\"\u001B[39m\u001B[33msummary_variables\u001B[39m\u001B[33m\"\u001B[39m](summary_variables, stage=stage)\n\u001B[32m--> \u001B[39m\u001B[32m252\u001B[39m summary_metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msummary_network\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_variables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstage\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    253\u001B[39m summary_outputs = summary_metrics.pop(\u001B[33m\"\u001B[39m\u001B[33moutputs\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m summary_metrics, summary_outputs\n",
      "\u001B[31mTypeError\u001B[39m: Trainer.compute_metrics() got an unexpected keyword argument 'stage'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec6616b9815cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesFlowDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
